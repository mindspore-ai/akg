#operator quant_batch_matmul
quant_batch_matmul:
  args:
    x1:
      dtype: tensor
    x2:
      dtype: tensor
    scale:
      dtype: tensor
    offset:
      dtype: tensor
      default: None
    bias:
      dtype: tensor
      default: None
    pertoken_scale:
      dtype: tensor
      default: None
    transpose_x1:
      dtype: bool
      default: false
    transpose_x2:
      dtype: bool
      default: false
    x2_format:
      dtype: str
      default: "'ND'"
    output_dtype:
      dtype: TypeId
      default: mstype.float16
      arg_handler: dtype_to_type_id
  args_signature:
        dtype_group: (x1, x2)
  returns:
    y:
      dtype: tensor
