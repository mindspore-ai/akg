import os
import json
import numpy as np
from typing import Union, Literal, List, Tuple, Any

# Framework imports (generated by FrameworkAdapter)
{% for line in framework_imports %}
{{ line }}
{% endfor %}
{% for line in framework_model_import %}
{{ line }}
{% endfor %}
TensorType = {{ tensor_type_name }}

{% if framework == "mindspore" %}
MS_TO_NP_DTYPE_MAP = {
    ms.float32: np.float32,
    ms.float16: np.float16,
    ms.bfloat16: np_dtype.bfloat16,
    ms.int8: np.int8,
    ms.int16: np.int16,
    ms.int32: np.int32,
    ms.int64: np.int64,
    ms.uint8: np.uint8,
    ms.uint16: np.uint16,
    ms.uint32: np.uint32,
    ms.uint64: np.uint64,
    ms.bool_: np.bool_,
}
{% endif %}

# DSL imports (generated by DSLAdapter)
{% for line in dsl_imports %}
{{ line }}
{% endfor %}
{% for line in dsl_impl_import %}
{{ line }}
{% endfor %}

# Special setup code (e.g., tilelang cache clear, triton patches)
{% for line in special_setup_code %}
{{ line }}
{% endfor %}

# Binary I/O functions (only for SWFT)
{% if needs_binary_io %}
{% for line in binary_io_functions %}
{{ line }}
{% endfor %}
{% endif %}

def run_generation_implementations():
    """运行生成实现"""
    # 获取运行模式
    backend = "{{ backend }}"  # 计算设备后端
    arch = "{{ arch }}"  # 硬件架构
    dsl = "{{ dsl }}"  # 实现方式
    
    # 设备设置 (generated by FrameworkAdapter)
{% for line in device_setup_code %}
    {{ line }}
{% endfor %}
    
    # 设置随机种子 (generated by FrameworkAdapter)
    {% for line in set_seed_code %}
    {{ line }}
    {% endfor %}

    # 获取初始化参数和输入数据
    init_params = get_init_inputs()
    
    # 设置随机种子以确保framework_model和impl_model的权重一致
    {% for line in set_seed_code %}
    {{ line }}
    {% endfor %}
    
    framework_model = FrameworkModel(*init_params)
    
    {% if framework == "torch" %}
    framework_model = framework_model.to(device)
    {% endif %}
    
    # 创建 impl_model（用于 ModelNew 类格式的 DSL）
    {% for line in create_impl_code %}
    {{ line }}
    {% endfor %}
    
    # 输入处理函数 (generated by FrameworkAdapter)
{% for line in process_input_code %}
    {{ line }}
{% endfor %}
    
    def run_benchmark(inputs, case_idx=0):
        """运行基准测试"""
{% for line in benchmark_code %}
        {{ line }}
{% endfor %}

        return execution_time_ms, method
    
    {% if is_dynamic_shape %}
    # 动态shape：获取多组输入数据
    inputs_list = get_inputs_dyn_list()
    
    # 对每组输入进行性能测试
    all_execution_times = []
    for case_idx, inputs in enumerate(inputs_list):
        {% if framework == "torch" %}
        inputs = [process_input(x) for x in inputs]
        {% endif %}
        
        execution_time, method = run_benchmark(inputs, case_idx=case_idx)
        all_execution_times.append(execution_time)
        print(f"[{{ op_name }}] Case {case_idx + 1} execution time: {execution_time * 1000:.4f} us")
    
    # 计算平均执行时间
    avg_execution_time = sum(all_execution_times) / len(all_execution_times)
    
    # 保存时间结果到文件
    result_data = {
        "execution_time_ms": avg_execution_time,
        "execution_time_us": avg_execution_time * 1000,
        "case_count": len(inputs_list),
        "case_times": all_execution_times,
        "warmup_times": {{ warmup_times }},
        "run_times": {{ run_times }},
        "method": method,
        "shape_type": "dynamic"
    }
    
    print(f"[{{ op_name }}] Average execution time: {avg_execution_time * 1000:.4f} us")
    
    {% else %}
    # 静态shape：获取单组输入数据
    {% if framework == "torch" %}
    inputs = get_inputs()
    inputs = [process_input(x) for x in inputs]
    {% elif framework == "numpy" %}
    inputs = get_inputs()
    {% elif framework == "mindspore" %}
    inputs = get_inputs()
    {% endif %}
    
    execution_time, method = run_benchmark(inputs, case_idx=0)
    
    # 保存时间结果到文件
    result_data = {
        "execution_time_ms": execution_time,
        "execution_time_us": execution_time * 1000,
        "warmup_times": {{ warmup_times }},
        "run_times": {{ run_times }},
        "method": method,
        "shape_type": "static"
    }
    
    print(f"[{{ op_name }}] Generation execution time: {execution_time * 1000:.4f} us")
    {% endif %}
    
    with open("generation_profile_result.json", "w") as f:
        json.dump(result_data, f, indent=2)

if __name__ == "__main__":
    run_generation_implementations()

