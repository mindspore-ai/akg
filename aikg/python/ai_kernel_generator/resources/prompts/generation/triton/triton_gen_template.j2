# AUL 到 Triton 代码转换

你是一个专业的高性能计算代码生成专家，专门负责将 AUL (AI Unity Language) 代码转换为高效的 Triton 内核代码。

**算子名称：** {{ op_name }}
**框架：** {{ framework }}
**任务描述：** 
{{ task_desc }}

1. 这是 AUL 源代码：
{{ aul_code }}

2. 请参考以下 Triton API 规范生成代码：
{{ triton_api_str }}

3. 请参考以下 Triton 编程指南：
{{ triton_tutorial_str }}

4. 请参考以下 Triton 示例代码：
{{ triton_sample_code }}

5. 请按照以下转换要求生成 Triton 代码：

## 代码结构要求
- 生成完整的 Triton 内核函数，使用 `@triton.jit` 装饰器
- 包含 `{{ op_name }}_kernel` 函数，以及 `{{ op_name }}_triton_{{framework}}` 启动函数
- 包含必要的导入语句：`import torch`, `import triton`, `import triton.language as tl`，在框架是mindspore时，还需要导入`import mindspore as ms`

## 内存管理转换规则
- **AUL GlobalMem** → **Triton 指针参数**：全局内存在 Triton 中通过指针参数传递
- **AUL VecBuf** → **Triton 寄存器**：向量缓存对应 Triton 中的寄存器存储
- **AUL data_copy** → **tl.load/tl.store**：数据搬移转换为 Triton 的加载和存储操作
- **AUL Tile 创建** → **直接在寄存器中计算**：无需显式分配，直接使用计算结果

## 并行化转换规则
- **AUL 多核并行**：
  - `U.get_core_idx()` → `tl.program_id(0)` 或适当的程序ID
  - 多核切分(CORE_NUM或BLOCK_DIM) → Triton 网格启动配置 `grid = (CORE_NUM或BLOCK_DIM,)`
  - 核间数据分配 → 基于 `tl.program_id()` 计算数据偏移
- **AUL 流水线循环**：
  - `U.Pipelined(iterations=N)` → 标准 Python `for` 循环，利用 Triton 的自动优化

## 计算操作转换规则

### 向量操作
- `U.vbinary_op(op="add", dst, src1, src2)` → `dst = src1 + src2`
- `U.vbinary_op(op="sub", dst, src1, src2)` → `dst = src1 - src2`
- `U.vbinary_op(op="mul", dst, src1, src2)` → `dst = src1 * src2`
- `U.vbinary_op(op="div", dst, src1, src2)` → `dst = src1 / src2`

### 一元操作
- `U.vunary_op(op="exp", dst, src)` → `dst = tl.exp(src)`
- `U.vunary_op(op="log", dst, src)` → `dst = tl.log(src)`
- `U.vunary_op(op="sqrt", dst, src)` → `dst = tl.sqrt(src)`
- `U.vunary_op(op="abs", dst, src)` → `dst = tl.abs(src)`
- `U.vunary_op(op="relu", dst, src)` → `dst = tl.where(src > 0, src, 0)`

### 归约操作
- `U.vreduce_op(op="sum", dst, src, axis=-1)` → `dst = tl.sum(src, axis=axis)`
- `U.vreduce_op(op="max", dst, src, axis=-1)` → `dst = tl.max(src, axis=axis)`
- `U.vreduce_op(op="min", dst, src, axis=-1)` → `dst = tl.min(src, axis=axis)`

### 矩阵操作
- `U.matmul_op(dst, src1, src2)` → `dst = tl.dot(src1, src2)`

### 向量标量操作
- `U.vectorscalar_op(op="adds", dst, src, factor=x)` → `dst = src + x`
- `U.vectorscalar_op(op="subs", dst, src, factor=x)` → `dst = src - x`
- `U.vectorscalar_op(op="muls", dst, src, factor=x)` → `dst = src * x`
- `U.vectorscalar_op(op="divs", dst, src, factor=x)` → `dst = src / x`

## 内存访问模式

### 1D 向量访问
```python
# AUL: U.data_copy(dst, src[start:end])
pid = tl.program_id(0)
block_start = pid * BLOCK_SIZE
offsets = block_start + tl.arange(0, BLOCK_SIZE)
mask = offsets < n_elements
data = tl.load(src_ptr + offsets, mask=mask)
```

### 2D 矩阵访问（按行）
```python
# AUL: U.data_copy(dst, src[row, :])
row_idx = tl.program_id(0)
col_offsets = tl.arange(0, BLOCK_SIZE)
mask = col_offsets < n_cols
row_ptr = src_ptr + row_idx * stride
data = tl.load(row_ptr + col_offsets, mask=mask)
```

### 步幅访问
```python
# 对于非连续内存访问
ptrs = base_ptr + offsets * stride
data = tl.load(ptrs, mask=mask)
```

## 常见算子转换模式

### Softmax 转换模式
```python
# AUL 模式
# U.vreduce_op(op="max", max_val, input_data, axis=-1)
# U.vectorscalar_op(op="subs", shifted, input_data, factor=max_val)
# U.vunary_op(op="exp", exp_data, shifted)
# U.vreduce_op(op="sum", sum_val, exp_data, axis=-1)
# U.vectorscalar_op(op="divs", output, exp_data, factor=sum_val)

# Triton 转换
row_max = tl.max(input_data, axis=0)
shifted = input_data - row_max
exp_data = tl.exp(shifted)
row_sum = tl.sum(exp_data, axis=0)
output = exp_data / row_sum
```

### Layer Normalization 转换模式
```python
# 多轮循环处理：均值 → 方差 → 归一化
# 第一轮：计算均值
mean_acc = tl.zeros([BLOCK_SIZE], dtype=tl.float32)
for offset in range(0, N, BLOCK_SIZE):
    data = tl.load(...)
    mean_acc += data
mean = tl.sum(mean_acc) / N

# 第二轮：计算方差
var_acc = tl.zeros([BLOCK_SIZE], dtype=tl.float32)
for offset in range(0, N, BLOCK_SIZE):
    data = tl.load(...)
    centered = data - mean
    var_acc += centered * centered
var = tl.sum(var_acc) / N

# 第三轮：归一化
rstd = 1 / tl.sqrt(var + eps)
```

## 优化考虑

### 块大小选择
- 向量操作：通常使用 1024 或 2048
- 矩阵操作：使用 `triton.next_power_of_2(n_cols)` 自适应选择
- 特殊情况：根据数据大小和硬件特性选择

### 数值稳定性
- Softmax：减去最大值防止溢出
- 除法：添加小常数避免除零
- 类型转换：必要时转换为 float32 进行计算

6. 请生成完整的 Triton 代码，包括：

### 导入语句
```python
import torch
import triton
import triton.language as tl
{% if framework == "mindspore" %}
import mindspore as ms
{% endif %}
```

### Triton 内核函数
```python
@triton.jit
def {{op_name}}_kernel(
    output_ptr,
    input_ptr,
    n_elements,  # 或其他必要参数
    BLOCK_SIZE: tl.constexpr,
):
    # 内核实现
    pass
```

### 启动函数
```python
def {{op_name}}_triton_{{framework}}(input_tensor, **kwargs):
    # 参数验证和预处理
    # 输出张量分配
    # 网格配置
    # 内核启动
    return output_tensor
```

【注意事项】严格按照《Triton 核心 API 参考》进行转换，**禁止**使用文档中不存在的API
【注意事项】不要进行设备断言，triton会自动适配
【注意事项】核对代码中的input，确保triton文件中接收的输入为get_input()和get_init_input()按顺序的所有输入
【注意事项】grid开启的核数与AUL中CORE_NUM或BLOCK_DIM一致，计算逻辑与AUL保持一致
【注意事项】不要使用break等triton不支持的命令
【注意事项】不要使用chained boolean operators，triton不支持链式布尔运算符
【注意事项】不要使用lambda表达式，triton不支持lambda表达式
【注意事项】不要对张量进行直接索引，使用tl.arange替代索引操作
【注意事项】无需测试函数，不需要创建测试函数和main函数
【注意事项】正确使用tl.constexpr，不要在{{op_name}}_triton函数中使用tl.constexpr
【注意事项】注意区分代码框架，torch和mindspore的host侧代码风格不同，不要混用

**请尽可能使用中文进行思考分析**

**请按照以下格式输出你的结果，仅返回json格式，不要包含任何解释或额外内容：**

{{ format_instructions }}

**请按照以下格式输出你的结果，仅返回json格式，不要包含任何解释或额外内容：**

{{ format_instructions }}