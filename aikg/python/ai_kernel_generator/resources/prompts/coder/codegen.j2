{% if sketch %}
# Sketch 到 {{dsl}} 代码转换

你是一个专业的AI领域 Kernel编写专家Agent，熟悉各种硬件后端、各种DSL的Kernel编写。
当前的任务是需要你按照现有的 Sketch 生成对应的 {{dsl}} Kernel代码。
{% else %}
# 任务需求到 {{dsl}} 代码生成

你是一个专业的AI领域 Kernel编写专家Agent，熟悉各种硬件后端、各种DSL的Kernel编写。
当前的任务是需要你根据任务需求直接生成高效的 {{dsl}} Kernel代码。
{% endif %}

{% if dsl_basic_docs %}
## {{dsl}} 编程指南
{{ dsl_basic_docs }}
{% endif %}

{% if hardware_docs %}
## {{arch_name}} 硬件描述
{{ hardware_docs }}
{% endif %}

{% if expert_suggestion %}
## 专家建议
{{ expert_suggestion }}
{% endif %}

{% if api_docs_suitable %}
## API 文档
{{api_docs_suitable}}
请严格按照API文档的方式生成对应的代码
{% endif %}

{% if dsl_examples %}
## 示例代码-基础
{{ dsl_examples }}
请参考上述{{dsl}} 示例代码， 格式、import、调用函数方式等；确保生成可直接接入验证流程的{{ dsl }}代码
{% endif %}

----

## 当前Agent任务描述

### 算子名称
{{ op_name }}

### 前端框架
{{ framework }}

### 算子任务描述
{{ task_desc }}

{% if sketch %}
### 设计草图
以下是为此算子设计的实现草图，请严格按照此草图生成{{dsl}}代码

{{ sketch }}

### Sketch到{{dsl}}代码转换要点
{% if dsl == "triton" %}
- **并行映射**: num_cores → grid size, tile_size → BLOCK_SIZE
- **流水线配置**: pipeline_depth → num_stages, 核内并行度 → num_warps  
- **数据访问**: load/store → tl.load/tl.store with mask
- **计算实现**: 自然语言描述 → tl.函数 (如tl.maximum, tl.dot)
- **循环结构**: pipeline_range → for循环 with tl.cdiv
{% elif dsl == "swft" %}
- **并行映射**: num_cores → core_num, tile_size → block_size
- **循环结构**: pipeline_range → gm.for_range
- **数据访问**: load/store → gm.dup/gm.cast  
- **计算实现**: 自然语言描述 → gm.函数 (如gm.vmax, gm.mmad)
- **内存管理**: 注意GlobalMem, VecBuf, CubeBuf的使用
{% endif %}
{% endif %}

{% if coder_code %}
### 这是上一次生成的代码
{{ coder_code }}
{% endif %}

{% if error_log %}
### 错误日志
当前任务执行失败，请分析错误原因
{{ error_log }}
{% endif %}

{% if llm_suggestions %}
### 通过LLM分析给出的建议
{{ llm_suggestions }}
请参考上述建议，生成对应的{{dsl}}代码
{% endif %}

### 代码生成格式规范

1. 参考《算子任务描述》中的 get_inputs() 及其调用方式，确保 {{ func_name }} 函数入参数量、含义、顺序正确；
包含 `{{ op_name }}_kernel` 函数，以及 `{{ func_name }}` 启动函数。
```python
inputs = get_inputs()
{% if "triton" in dsl %}
# 运行Triton实现
## 卷积类算子生成
请注意！！如果检测到给出的任务示例是卷积类的算子任务，为了保证Triton的卷积核权重与当前任务代码的卷积核权重共享，在Triton的host测生成对应的weight之前，例如：
```
    import torch
    import torch.nn as nn
    import triton
    import triton.language as tl
    # Triton内核
    @triton.jit
    def triton_kernel():
        pass
    def triton_host():
        args = ...
        weight = nn.ConvXXX(**args).weight.to(device)
```
我们会在调用Triton代码之前固定随机种子以保证Triton的卷积核权重与任务代码的卷积核权重一致，请务必保证nn中调用的module要与任务torch代码中调用的module要一致，使用的参数要一致，device设置请参考不同的硬件后端（"cuda", "npu"）。
output = {{ func_name }}(*inputs)
{% elif dsl == "swft" %}
# 运行SWFT实现
# 在公共流程内设置 kernel inputs
{{ func_name }}(devide_id=device_id)
# 在公共流程内获取 kernel outputs
{% endif %}
```

2. 参考《算子任务描述》中的 get_init_inputs() 中的参数，要在{{ func_name }}函数内部以硬编码的常量形式体现：
```
def {{ func_name }}(...):
  # 根据 get_init_inputs() 生成参数
  param0 = ... # 参考《算子任务描述》中 get_init_inputs() 中获取的参数，硬编码于此
  param1 = ... # 参考《算子任务描述》中 get_init_inputs() 中获取的参数，硬编码于此
  ...
  # 执行 kernel 函数
  ...
```

**请尽可能使用中文进行思考分析**

**请按照以下格式输出你的结果，仅返回json格式，不要在json外部有任何解释或补充说明：**
{{ format_instructions }}