# CUDA C 专家技巧与优化建议

本文档提供 CUDA C 开发的技巧、性能优化和问题排查指南。

## 1. 性能优化

### 块大小选择策略
- **基础**: 2的幂（128, 256, 512, 1024）
- **推荐**: 256 或 512 线程每块
- **调优**: 平衡并行度与资源占用，避免过大或过小
- **限制**: 每块最多1024线程（大多数GPU）

### 内存访问优化
- **合并访问**: 连续线程访问连续内存地址
- **对齐访问**: 数据按128字节边界对齐
- **避免bank冲突**: 共享内存访问避免同一bank
- **使用纹理内存**: 随机访问模式的数据

### 计算优化
- **避免分支发散**: 同一warp内线程执行相同路径
- **使用内置函数**: `__expf()`, `__logf()` 等快速数学函数
- **减少原子操作**: 尽量使用归约而非原子操作

## 2. 数值稳定性技巧

### 防溢出处理
```cuda
// 归一化前先减去最大值
float max_val = input[0];
for (int i = 1; i < n; i++) {
    max_val = fmaxf(max_val, input[i]);
}
float stable_data = input[i] - max_val;
float exp_data = __expf(stable_data);
```

### 精度提升
- **中间计算**: 计算时精度没必要提升到double，使用float类型就可以
- **累加操作**: 使用高精度累加器防止精度丢失
- **避免数值下溢**: 检查除零和开方操作

## 3. 编程约束与最佳实践

### 必须遵循的规则
- **边界检查**: 所有数组访问前必须检查边界
- **错误检查**: 每个CUDA API调用后检查返回值
- **内存对齐**: 确保数据按合适边界对齐
- **线程同步**: 共享内存使用前后必须同步

### 内核设计原则
- **单一职责**: 每个内核只做一件事
- **参数简单**: 避免复杂的数据结构传递
- **内存局部性**: 尽量访问相邻内存位置
- **避免动态分配**: 内核内不使用malloc/new

## 4. 调试与排查清单

### 内存访问问题
- [ ] 所有数组访问是否都有边界检查？
- [ ] 内存是否正确分配和释放？
- [ ] 主机设备内存拷贝方向是否正确？
- [ ] 指针是否在有效范围内？

### 内核执行问题  
- [ ] 网格和块大小是否合理？
- [ ] 内核启动参数是否正确？
- [ ] 是否有未检查的CUDA错误？
- [ ] 设备内存是否足够？

### 性能问题
- [ ] 块大小是否为2的幂？
- [ ] 内存访问是否合并？
- [ ] 是否避免了分支发散？
- [ ] 共享内存使用是否高效？

## 5. 常见错误速查

| 错误类型 | 症状 | 解决方案 |
|---------|------|---------|
| 越界访问 | 运行时错误或结果异常 | 添加边界检查 |
| 内存泄漏 | 程序内存持续增长 | 检查cudaFree调用 |
| 同步错误 | 结果不确定 | 添加__syncthreads() |
| 类型不匹配 | 编译错误 | 检查数据类型转换 |
| 设备内存不足 | 内核启动失败 | 减少块大小或分批处理 |

## 6. 开发建议
### 注意！在生成算子的时候在Python模块中内嵌CUDA C代码，使用Python的JIT编译方式

### 代码风格
- 添加充分的注释说明计算逻辑
- 使用描述性的变量名
- 保持内核函数简洁明了
- 统一的错误处理模式

### 7. 注意事项
- 生成的内核代码不要包含任何测试代码片段
- 禁止有任何打印的语句printf()、throw std::runtime_error()等
