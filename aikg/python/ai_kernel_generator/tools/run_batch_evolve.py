# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import sys
import subprocess
import json
import asyncio
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import traceback
from ai_kernel_generator import get_project_root

# ============================================================================
# æ‰¹é‡æ‰§è¡Œé…ç½®å‚æ•° - åœ¨æ­¤å¤„ä¿®æ”¹æ‰¹é‡æ‰§è¡Œçš„é…ç½®
# ============================================================================

# åŸºç¡€è¿›åŒ–å‚æ•°é…ç½® - å¯¹æ‰€æœ‰ä»»åŠ¡ç”Ÿæ•ˆ
EVOLVE_BASE_CONFIG = {
    "dsl": "triton",           # å®ç°ç±»å‹: triton, swft, etc.
    "framework": "torch",      # æ¡†æ¶: torch, numpy, mindspore, etc.
    "backend": "ascend",       # åç«¯: ascend, cuda, etc.
    "arch": "ascend910b4"      # æ¶æ„: a100, ascend910b4, etc.
}

# æ‰¹é‡å¹¶è¡Œé…ç½®
BATCH_PARALLEL_NUM = 2  # batchçº§åˆ«çš„å¹¶è¡Œæ•°ï¼ˆåŒæ—¶è¿è¡Œçš„evolveä»»åŠ¡æ•°ï¼‰

# ä»»åŠ¡ç›®å½•å’Œè¾“å‡ºç›®å½•é…ç½®
TASK_DIR = "Path/to/your/tasks"  # ä»»åŠ¡æ–‡ä»¶ç›®å½• - è¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„
OUTPUT_DIR = "Path/to/your/batch_results"  # è¾“å‡ºç›®å½• - è¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„

# è®¾å¤‡æ± é…ç½®ï¼ˆå¾ªç¯åˆ†é…ç»™ä¸åŒä»»åŠ¡ï¼Œé¿å…å¹¶è¡Œå†²çªï¼‰
# æ¯ä¸ªä»»åŠ¡ä¼šåˆ†é…ä¸€ä¸ªè®¾å¤‡ï¼Œæ•°é‡éœ€è¦å¤§äºç­‰äºå¹¶è¡Œæ•°
DEVICE_POOL = [4, 5]  # å¯ç”¨è®¾å¤‡åˆ—è¡¨

# é»˜è®¤ä»»åŠ¡é…ç½®
DEFAULT_TASK_CONFIG = {
    "max_rounds": 2,
    "parallel_num": 2
}

# æ¯ä¸ªä»»åŠ¡çš„è‡ªå®šä¹‰é…ç½®ï¼ˆå¯é€‰ï¼‰
# æ ¼å¼ï¼š{ä»»åŠ¡å: EvolveConfigå‚æ•°å­—å…¸}
TASK_CUSTOM_CONFIGS = {
    # ç¤ºä¾‹ï¼šä¸ºç‰¹å®šä»»åŠ¡é…ç½®ä¸åŒå‚æ•°
    # "relu_task": {"max_rounds": 3, "parallel_num": 1},
    # "add_task": {"max_rounds": 2, "parallel_num": 2},
}


class BatchTaskPool:
    """æ‰¹é‡ä»»åŠ¡æ± ï¼Œç”¨äºç®¡ç†å¹¶è¡Œæ‰§è¡Œçš„evolveä»»åŠ¡"""

    def __init__(self, max_concurrency: int, device_pool: List[int]):
        self.max_concurrency = max_concurrency
        self.semaphore = asyncio.Semaphore(max_concurrency)
        # åŠ¨æ€è®¾å¤‡æ± ç®¡ç†
        self.available_devices = asyncio.Queue()
        self.device_lock = asyncio.Lock()

        # åˆå§‹åŒ–è®¾å¤‡æ± 
        for device in device_pool:
            self.available_devices.put_nowait(device)

    async def acquire_device(self) -> int:
        """è·å–å¯ç”¨è®¾å¤‡"""
        async with self.device_lock:
            device = await self.available_devices.get()
            return device

    async def release_device(self, device: int):
        """é‡Šæ”¾è®¾å¤‡å›æ± ä¸­"""
        async with self.device_lock:
            await self.available_devices.put(device)

    async def run_task_async(self, task_file: Path, output_dir: Path, index: int, total: int,
                             use_compact_output: bool = False) -> Dict[str, Any]:
        """å¼‚æ­¥è¿è¡Œå•ä¸ªä»»åŠ¡"""
        # è·å–è®¾å¤‡
        device = await self.acquire_device()

        if not use_compact_output:
            print(f"ğŸ¯ ä»»åŠ¡ [{index}/{total}] {task_file.stem} åˆ†é…åˆ°è®¾å¤‡ {device}")

        try:
            async with self.semaphore:
                # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„ä»»åŠ¡
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    run_single_task_subprocess,
                    task_file, output_dir, index, total, use_compact_output, device
                )
                return result
        finally:
            # ç¡®ä¿è®¾å¤‡è¢«é‡Šæ”¾
            await self.release_device(device)
            if not use_compact_output:
                print(f"â™»ï¸  ä»»åŠ¡ {task_file.stem} å®Œæˆï¼Œè®¾å¤‡ {device} å·²å›æ”¶")

    async def run_batch_parallel(self, task_files: List[Path], output_dir: Path) -> List[Dict[str, Any]]:
        """å¹¶è¡Œè¿è¡Œæ‰¹é‡ä»»åŠ¡"""
        use_compact_output = self.max_concurrency > 1

        if use_compact_output:
            print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œæ‰§è¡Œï¼Œæœ€å¤§å¹¶å‘æ•°: {self.max_concurrency}")

        # ä½¿ç”¨å·¥ä½œè€…é˜Ÿåˆ—æ¨¡å¼é¿å…è®¾å¤‡æ•°ä¸è¶³æ—¶çš„æ­»é”
        task_queue = asyncio.Queue()
        results = [None] * len(task_files)

        # å°†æ‰€æœ‰ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
        for i, task_file in enumerate(task_files):
            await task_queue.put((i, task_file))

        # å·¥ä½œè€…å‡½æ•°
        async def worker():
            while True:
                try:
                    # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼Œè¶…æ—¶é€€å‡ºé¿å…æ— é™ç­‰å¾…
                    task_index, task_file = await asyncio.wait_for(
                        task_queue.get(), timeout=1.0
                    )

                    # æ‰§è¡Œä»»åŠ¡
                    result = await self.run_task_async(
                        task_file, output_dir, task_index + 1, len(task_files), use_compact_output
                    )

                    # ä¿å­˜ç»“æœ
                    results[task_index] = result
                    task_queue.task_done()

                except asyncio.TimeoutError:
                    # é˜Ÿåˆ—ä¸ºç©ºï¼Œå·¥ä½œè€…é€€å‡º
                    break
                except Exception as e:
                    # å¤„ç†å¼‚å¸¸ï¼Œç¡®ä¿ä»»åŠ¡æ ‡è®°å®Œæˆ
                    if 'task_index' in locals():
                        results[task_index] = {
                            'op_name': task_file.stem,
                            'task_file': str(task_file),
                            'success': False,
                            'execution_time': 0,
                            'error': f"Worker exception: {str(e)}",
                            'start_time': datetime.now().isoformat(),
                            'end_time': datetime.now().isoformat()
                        }
                        task_queue.task_done()

        # åˆ›å»ºå·¥ä½œè€…
        workers = []
        for _ in range(self.max_concurrency):
            workers.append(asyncio.create_task(worker()))

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await task_queue.join()

        # æ¸…ç†å·¥ä½œè€…
        for worker_task in workers:
            worker_task.cancel()
        await asyncio.gather(*workers, return_exceptions=True)

        # è¿”å›ç»“æœï¼ˆå¼‚å¸¸å·²åœ¨å·¥ä½œè€…å†…éƒ¨å¤„ç†ï¼‰
        return [r for r in results if r is not None]


def discover_task_files(task_dir: str) -> List[Path]:
    """å‘ç°æ‰€æœ‰ä»»åŠ¡æ–‡ä»¶"""
    task_path = Path(task_dir)
    if not task_path.exists():
        raise FileNotFoundError(f"ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨: {task_dir}")

    task_files = list(task_path.glob("*.py"))
    task_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº

    print(f"ğŸ“ å‘ç° {len(task_files)} ä¸ªä»»åŠ¡æ–‡ä»¶:")
    for i, file_path in enumerate(task_files, 1):
        print(f"  {i}. {file_path.name}")

    return task_files


def run_single_task_subprocess(task_file: Path, output_dir: Path, index: int, total: int,
                               use_compact_output: bool = False, device: int = 5) -> Dict[str, Any]:
    """ä½¿ç”¨subprocessæ–¹å¼è¿è¡Œå•ä¸ªä»»åŠ¡"""
    op_name = "aikg_" + task_file.stem

    if not use_compact_output:
        print(f"\n" + "="*80)
        print(f"ğŸ“‹ å¼€å§‹æ‰§è¡Œä»»åŠ¡ [{index}/{total}]: {op_name}")
        print("="*80)
    else:
        print(f"ğŸ”„ [{index}/{total}] {op_name}")

    start_time = datetime.now()

    # å‡†å¤‡è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä»»åŠ¡å®Œæˆåä¿å­˜ï¼‰
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / f"output_{op_name}_{start_time.strftime('%Y%m%d_%H%M%S')}.txt"

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
        tools_dir = Path(get_project_root()) / "tools"
        single_evolve_script = tools_dir / "single_evolve_runner.py"

        if not tools_dir.exists():
            raise FileNotFoundError(f"toolsç›®å½•ä¸å­˜åœ¨: {tools_dir}")

        if not single_evolve_script.exists():
            raise FileNotFoundError(f"single_evolve_runner.pyä¸å­˜åœ¨: {single_evolve_script}")

        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        absolute_task_file = Path(task_file).resolve()

        # è·å–ä»»åŠ¡é…ç½®
        max_rounds = DEFAULT_TASK_CONFIG["max_rounds"]
        parallel_num = DEFAULT_TASK_CONFIG["parallel_num"]

        # åº”ç”¨ä»»åŠ¡ç‰¹å®šé…ç½®
        if op_name in TASK_CUSTOM_CONFIGS:
            custom_config = TASK_CUSTOM_CONFIGS[op_name]
            max_rounds = custom_config.get('max_rounds', max_rounds)
            parallel_num = custom_config.get('parallel_num', parallel_num)

        # æ„å»ºå‘½ä»¤ - ä¼ é€’å®Œæ•´çš„é…ç½®å‚æ•°
        cmd = [
            sys.executable, str(single_evolve_script),
            op_name,                                    # 1. ç®—å­åç§°
            str(absolute_task_file),                   # 2. ä»»åŠ¡æ–‡ä»¶è·¯å¾„
            str(device),                               # 3. è®¾å¤‡ID
            str(max_rounds),                           # 4. æœ€å¤§è½®æ•°
            str(parallel_num),                         # 5. å¹¶è¡Œæ•°
            EVOLVE_BASE_CONFIG["dsl"],                 # 6. DSLç±»å‹
            EVOLVE_BASE_CONFIG["framework"],           # 7. æ¡†æ¶
            EVOLVE_BASE_CONFIG["backend"],             # 8. åç«¯
            EVOLVE_BASE_CONFIG["arch"]                 # 9. æ¶æ„
        ]

        # æ ¹æ®è¾“å‡ºæ¨¡å¼é€‰æ‹©æ‰§è¡Œæ–¹å¼
        if use_compact_output:
            # ç²¾ç®€æ¨¡å¼ï¼šé™é»˜æ‰§è¡Œï¼Œåªæ•è·è¾“å‡ºç”¨äºè§£æ
            subprocess_result = subprocess.run(cmd, capture_output=True, text=True, env=env, errors='replace')
            result = {
                'returncode': subprocess_result.returncode,
                'stdout': subprocess_result.stdout,
                'stderr': subprocess_result.stderr
            }
        else:
            # è¯¦ç»†æ¨¡å¼ï¼šå®æ—¶æ˜¾ç¤ºæ‰€æœ‰è¾“å‡ºå¹¶å®æ—¶å†™å…¥æ–‡ä»¶
            print(f"ğŸ”„ å¼€å§‹è¿›åŒ–è¿‡ç¨‹ï¼Œå®æ—¶è¾“å‡º:")
            print("-" * 60)

            try:
                process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True, env=env, errors='replace', bufsize=1, universal_newlines=True)

                stdout_lines = []
                for line in iter(process.stdout.readline, ''):
                    line = line.rstrip()
                    if line:
                        print(f"  {line}")
                        stdout_lines.append(line)

                process.wait()
                # ç›´æ¥ä½¿ç”¨å­—å…¸å­˜å‚¨ç»“æœ
                result = {
                    'returncode': process.returncode,
                    'stdout': '\n'.join(stdout_lines),
                    'stderr': ""
                }
            except Exception as e:
                print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                subprocess_result = subprocess.run(cmd, capture_output=True, text=True, env=env, errors='replace')
                result = {
                    'returncode': subprocess_result.returncode,
                    'stdout': subprocess_result.stdout,
                    'stderr': subprocess_result.stderr
                }

                # å¦‚æœæ˜¯fallbackæ¨¡å¼ï¼Œä¹Ÿè¦å†™å…¥æ–‡ä»¶
                if output_file and result['stdout']:
                    try:
                        with open(output_file, 'a', encoding='utf-8') as f:
                            f.write(result['stdout'])
                            f.flush()
                    except Exception:
                        pass

            print("-" * 60)

        # åœ¨ç²¾ç®€æ¨¡å¼ä¸‹ï¼Œè§£æå¹¶æ˜¾ç¤ºå…³é”®ä¿¡æ¯ï¼ŒåŒæ—¶å®æ—¶å†™å…¥æ–‡ä»¶
        if use_compact_output and result['stdout']:
            lines = result['stdout'].split('\n')
            for line in lines:
                line_clean = line.strip()
                # åªæ˜¾ç¤ºå…³é”®çš„è½®æ¬¡ç»“æœå’Œæœ€ç»ˆç»“æœï¼Œè¿‡æ»¤æ‰çº¯åˆ†éš”çº¿å’Œå¸¦æ ‡è¯†ç çš„è¡Œ
                if any(keyword in line_clean for keyword in ['è½®æ¬¡', 'æœ€ç»ˆå…¨å±€æœ€ä½³åŠ é€Ÿæ¯”', 'ğŸš€ åŠ é€Ÿæ¯”ç»Ÿè®¡æ±‡æ€»', 'è¿›åŒ–å®Œæˆï¼æœ€ç»ˆç»“æœæ±‡æ€»']):
                    print(f"  {line_clean}")
                elif 'è¿›åŒ–å®Œæˆ' in line_clean and 'æœ€ç»ˆç»“æœæ±‡æ€»' in line_clean:
                    print(f"  {line_clean}")
                elif line_clean.startswith('ç®—å­åç§°:') or line_clean.startswith('æ€»è½®æ•°:') or line_clean.startswith('æˆåŠŸä»»åŠ¡æ•°:'):
                    print(f"  {line_clean}")
                # è·³è¿‡çº¯åˆ†éš”çº¿ã€å¸¦æ ‡è¯†ç çš„è¡Œã€ä»¥åŠå…¶ä»–æ ¼å¼åŒ–è¾“å‡º
                # elif line_clean and not (line_clean.startswith('=') or len(line_clean.split()) == 1 and '=' in line_clean):
                #     pass  # å…¶ä»–è¡Œæš‚æ—¶ä¸æ˜¾ç¤º

        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()

        # è§£æè¾“å‡ºä¸­çš„å…³é”®ä¿¡æ¯
        output_lines = result['stdout'].split('\n') if result['stdout'] else []
        success_rate = None
        best_speedup = None

        for line in output_lines:
            if "æœ€ç»ˆæˆåŠŸç‡:" in line or "å®Œæˆ" in line and "%" in line:
                try:
                    # å°è¯•ä»ä¸åŒæ ¼å¼ä¸­æå–æˆåŠŸç‡
                    if "æœ€ç»ˆæˆåŠŸç‡:" in line:
                        success_rate = float(line.split("æœ€ç»ˆæˆåŠŸç‡:")[1].split("%")[0].strip()) / 100
                    elif "å®Œæˆ" in line and "(" in line and "%" in line:
                        # åŒ¹é… "å®Œæˆ 2/4(50%)" æ ¼å¼
                        match = re.search(r'(\d+\.?\d*)%', line)
                        if match:
                            success_rate = float(match.group(1)) / 100
                except:
                    pass
            elif "æœ€ç»ˆå…¨å±€æœ€ä½³åŠ é€Ÿæ¯”:" in line or "æœ€ä½³:" in line:
                try:
                    if "æœ€ç»ˆå…¨å±€æœ€ä½³åŠ é€Ÿæ¯”:" in line:
                        best_speedup = float(line.split("æœ€ç»ˆå…¨å±€æœ€ä½³åŠ é€Ÿæ¯”:")[1].split("x")[0].strip())
                    elif "æœ€ä½³:" in line:
                        # åŒ¹é… "æœ€ä½³:1.23x" æ ¼å¼
                        match = re.search(r'æœ€ä½³:(\d+\.?\d*)x', line)
                        if match:
                            best_speedup = float(match.group(1))
                except:
                    pass

        # åˆ¤æ–­ä»»åŠ¡æ˜¯å¦çœŸæ­£æˆåŠŸï¼šè¿›ç¨‹æ­£å¸¸é€€å‡º ä¸” æœ‰æœ‰æ•ˆçš„åŠ é€Ÿæ¯”ç»“æœ
        task_success = (result['returncode'] == 0 and
                        best_speedup is not None and
                        best_speedup > 0.0)

        # ä»»åŠ¡å®Œæˆåä¿å­˜å®Œæ•´è¾“å‡ºåˆ°æ–‡ä»¶
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"ä»»åŠ¡åç§°: {op_name}\n")
                f.write(f"ä»»åŠ¡æ–‡ä»¶: {task_file}\n")
                f.write(f"å¼€å§‹æ—¶é—´: {start_time.isoformat()}\n")
                f.write(f"ç»“æŸæ—¶é—´: {end_time.isoformat()}\n")
                f.write(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’\n")
                f.write(f"è¿”å›ç : {result['returncode']}\n")
                f.write(f"ä»»åŠ¡æˆåŠŸ: {'æ˜¯' if task_success else 'å¦'}\n")
                if best_speedup is not None:
                    f.write(f"æœ€ä½³åŠ é€Ÿæ¯”: {best_speedup:.2f}x\n")
                f.write("\n" + "="*50 + " å®Œæ•´è¾“å‡º " + "="*50 + "\n")
                f.write(result['stdout'] or "")
                if result['stderr']:
                    f.write("\n" + "="*50 + " é”™è¯¯è¾“å‡º " + "="*50 + "\n")
                    f.write(result['stderr'])
        except Exception as e:
            print(f"âš ï¸  æ— æ³•ä¿å­˜è¾“å‡ºæ–‡ä»¶: {e}")
            output_file = None

        if result['returncode'] == 0:
            if task_success:
                if not use_compact_output:
                    print(f"âœ… ä»»åŠ¡ {op_name} æ‰§è¡ŒæˆåŠŸï¼Œæœ€ä½³åŠ é€Ÿæ¯”: {best_speedup:.2f}x")
            else:
                if not use_compact_output:
                    print(f"âš ï¸  ä»»åŠ¡ {op_name} è¿›ç¨‹æ­£å¸¸ç»“æŸï¼Œä½†æœªç”Ÿæˆæœ‰æ•ˆç®—å­ (åŠ é€Ÿæ¯”: {best_speedup or 0.0:.2f}x)")

            return {
                'op_name': op_name,
                'task_file': str(task_file),
                'success': task_success,
                'execution_time': execution_time,
                'return_code': result['returncode'],
                'success_rate': success_rate,
                'best_speedup': best_speedup or 0.0,
                'output_file': str(output_file) if output_file else None,
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat()
            }
        else:
            if use_compact_output:
                print(f"âŒ {op_name}: æ‰§è¡Œå¤±è´¥(ç :{result['returncode']})")
            else:
                print(f"âŒ ä»»åŠ¡ {op_name} æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result['returncode']}")
                # æ˜¾ç¤ºç®€è¦é”™è¯¯ä¿¡æ¯
                if result['stderr']:
                    stderr_lines = result['stderr'].strip().split('\n')[-3:]
                    for line in stderr_lines:
                        if line.strip():
                            print(f"   {line}")

            return {
                'op_name': op_name,
                'task_file': str(task_file),
                'success': False,
                'execution_time': execution_time,
                'return_code': result['returncode'],
                'error': f"Process failed with return code {result['returncode']}",
                'output_file': str(output_file) if output_file else None,
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat()
            }

    except Exception as e:

        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()

        error_msg = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
        print(f"âŒ {error_msg}")

        # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯åˆ°æ§åˆ¶å°ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        print("ğŸ”§ è¯¦ç»†é”™è¯¯å †æ ˆ:")
        traceback.print_exc()

        # ä¿å­˜å¼‚å¸¸ä¿¡æ¯åˆ°æ–‡ä»¶
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"ä»»åŠ¡åç§°: {op_name}\n")
                f.write(f"ä»»åŠ¡æ–‡ä»¶: {task_file}\n")
                f.write(f"å¼€å§‹æ—¶é—´: {start_time.isoformat()}\n")
                f.write(f"ç»“æŸæ—¶é—´: {end_time.isoformat()}\n")
                f.write(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’\n")
                f.write(f"ä»»åŠ¡æˆåŠŸ: å¦\n")
                f.write(f"é”™è¯¯ä¿¡æ¯: {error_msg}\n")
                f.write("\n" + "="*50 + " é”™è¯¯è¯¦æƒ… " + "="*50 + "\n")
                f.write(traceback.format_exc())
            print(f"ğŸ“ é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")
            error_file_path = str(output_file)
        except Exception as file_error:
            print(f"âš ï¸  æ— æ³•ä¿å­˜é”™è¯¯æ–‡ä»¶: {file_error}")
            error_file_path = None

        return {
            'op_name': op_name,
            'task_file': str(task_file),
            'success': False,
            'execution_time': execution_time,
            'error': error_msg,
            'error_file': error_file_path,
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat()
        }


def print_batch_summary(batch_results: List[Dict[str, Any]], total_start_time: datetime):
    """æ‰“å°æ‰¹é‡æ‰§è¡Œæ‘˜è¦"""
    successful_tasks = [r for r in batch_results if r.get('success', False)]
    failed_tasks = [r for r in batch_results if not r.get('success', False)]

    total_time = (datetime.now() - total_start_time).total_seconds()

    print("\n" + "="*100)
    print("ğŸ¯ æ‰¹é‡æ‰§è¡Œå®Œæˆï¼æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š")
    print("="*100)
    print(f"æ€»ä»»åŠ¡æ•°: {len(batch_results)}")
    print(f"æˆåŠŸä»»åŠ¡æ•°: {len(successful_tasks)}")
    print(f"å¤±è´¥ä»»åŠ¡æ•°: {len(failed_tasks)}")
    print(f"æˆåŠŸç‡: {len(successful_tasks)/len(batch_results):.2%}")
    print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’ ({total_time/3600:.2f}å°æ—¶)")

    # æ˜¾ç¤ºæˆåŠŸä»»åŠ¡çš„æ€§èƒ½ç»Ÿè®¡
    if successful_tasks:
        print(f"\nğŸ† æˆåŠŸä»»åŠ¡æ€§èƒ½ç»Ÿè®¡:")
        performance_data = []
        for task in successful_tasks:
            if task.get('best_speedup'):
                performance_data.append({
                    'name': task['op_name'],
                    'speedup': task['best_speedup'],
                    'success_rate': task.get('success_rate', 0),
                    'time': task.get('execution_time', 0)
                })

        if performance_data:
            performance_data.sort(key=lambda x: x['speedup'], reverse=True)
            for i, perf in enumerate(performance_data[:10], 1):
                print(f"  {i:2d}. {perf['name']:<20} - {perf['speedup']:6.2f}x "
                      f"(æˆåŠŸç‡: {perf['success_rate']:.1%}, æ—¶é—´: {perf['time']:.1f}s)")

    # æ˜¾ç¤ºå¤±è´¥ä»»åŠ¡
    if failed_tasks:
        print(f"\nâŒ å¤±è´¥ä»»åŠ¡åˆ—è¡¨:")
        for task in failed_tasks:
            error_msg = task.get('error', 'Unknown error')
            print(f"  â€¢ {task['op_name']}: {error_msg}")

    print("="*100)


def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨ç¡¬ç¼–ç é…ç½®
    task_dir = TASK_DIR
    output_dir = Path(OUTPUT_DIR)
    parallel_num = BATCH_PARALLEL_NUM

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)

    print("ğŸš€ å¼€å§‹æ‰¹é‡è¿›åŒ–æ‰§è¡Œ")
    print("="*80)
    print(f"ä»»åŠ¡ç›®å½•: {task_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"å¹¶è¡Œæ•°: {parallel_num}")
    print(f"è®¾å¤‡æ± : {DEVICE_POOL}")
    print("="*80)

    total_start_time = datetime.now()
    batch_results = []

    try:
        # å‘ç°æ‰€æœ‰ä»»åŠ¡æ–‡ä»¶
        task_files = discover_task_files(task_dir)

        if not task_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•.pyæ–‡ä»¶")
            return

        # åˆ›å»ºæ‰¹é‡ä»»åŠ¡æ± ï¼ˆä¼ å…¥è®¾å¤‡æ± ï¼‰
        batch_pool = BatchTaskPool(max_concurrency=parallel_num, device_pool=DEVICE_POOL)

        if parallel_num <= 1:
            print(f"\nğŸ“‹ å°†æŒ‰é¡ºåºæ‰§è¡Œ {len(task_files)} ä¸ªç®—å­çš„è¿›åŒ–æµç¨‹...")
        else:
            print(f"\nğŸš€ å°†å¹¶è¡Œæ‰§è¡Œ {len(task_files)} ä¸ªç®—å­çš„è¿›åŒ–æµç¨‹...")
            print(f"ğŸ“± è®¾å¤‡åŠ¨æ€åˆ†é…ï¼š{DEVICE_POOL} (ä»»åŠ¡å®Œæˆåè‡ªåŠ¨å›æ”¶)")

        # è¿è¡Œä»»åŠ¡
        try:
            batch_results = asyncio.run(batch_pool.run_batch_parallel(task_files, output_dir))
        except Exception as e:
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()
            return

        # ç”Ÿæˆå¹¶ä¿å­˜æ‰¹é‡æ‘˜è¦
        summary_data = {
            'batch_info': {
                'total_tasks': len(batch_results),
                'successful_tasks': len([r for r in batch_results if r.get('success', False)]),
                'failed_tasks': len([r for r in batch_results if not r.get('success', False)]),
                'total_execution_time_seconds': (datetime.now() - total_start_time).total_seconds(),
                'start_time': total_start_time.isoformat(),
                'end_time': datetime.now().isoformat()
            },
            'task_results': batch_results
        }

        summary_file = output_dir / f"batch_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)

        # æ‰“å°æ‘˜è¦
        print_batch_summary(batch_results, total_start_time)
        print(f"\nğŸ’¾ æ‰¹é‡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()
