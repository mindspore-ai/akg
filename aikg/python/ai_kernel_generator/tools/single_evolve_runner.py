# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import sys
from pathlib import Path
import json
from datetime import datetime
from ai_kernel_generator.core.evolve import evolve
from ai_kernel_generator.core.async_pool.task_pool import TaskPool
from ai_kernel_generator.core.async_pool.device_pool import DevicePool
from ai_kernel_generator.config.config_validator import load_config
from ai_kernel_generator.utils.environment_check import check_env_for_task
from ai_kernel_generator import get_project_root
from typing import Optional, List
from dataclasses import dataclass

# ============================================================================
# é…ç½®å‚æ•°ç±»
# ============================================================================


@dataclass
class EvolveConfig:
    """è¿›åŒ–é…ç½®å‚æ•°ç±»"""
    # åŸºæœ¬å‚æ•°
    dsl: str = "triton"
    framework: str = "torch"
    backend: str = "ascend"
    arch: str = "ascend910b4"

    # è¿›åŒ–å‚æ•°
    max_rounds: int = 2
    parallel_num: int = 2

    # è®¾å¤‡é…ç½®
    device_list: List[int] = None

    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_path: str = ""  # å°†åœ¨__post_init__ä¸­è®¾ç½®

    # ä»»åŠ¡é…ç½®
    op_name: Optional[str] = None
    task_desc: Optional[str] = None

    def __post_init__(self):
        if self.device_list is None:
            self.device_list = [5]
        if not self.config_path:
            self.config_path = str(Path(get_project_root()) / "config" / "vllm_triton_evolve_config.yaml")


# é»˜è®¤é…ç½®å®ä¾‹ - åœ¨æ­¤å¤„ä¿®æ”¹åŸºç¡€é…ç½®
DEFAULT_CONFIG = EvolveConfig(
    dsl="triton",
    framework="torch",
    backend="ascend",
    arch="ascend910b4",
    max_rounds=2,
    parallel_num=2,
    device_list=[5],
    config_path=""  # å°†åœ¨__post_init__ä¸­è‡ªåŠ¨è®¾ç½®
)

# é»˜è®¤ä»»åŠ¡é…ç½®
DEFAULT_OP_NAME = "relu_op"
DEFAULT_TASK_DESC = """import torch
import torch.nn as nn

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return torch.relu(x)

batch_size = 16
dim = 16384

def get_inputs():
    x = torch.randn(batch_size, dim)
    return [x]

def get_init_inputs():
    return []
"""


async def run_custom_evolve(op_name: str = None, task_desc: str = None, evolve_config: EvolveConfig = None):
    """è¿è¡Œè‡ªå®šä¹‰ä»»åŠ¡çš„è¿›åŒ–è¿‡ç¨‹

    Args:
        op_name: ç®—å­åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨evolve_configä¸­çš„é…ç½®
        task_desc: ä»»åŠ¡æè¿°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨evolve_configä¸­çš„é…ç½®
        evolve_config: è¿›åŒ–é…ç½®ç±»å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    """
    # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
    if evolve_config is None:
        evolve_config = DEFAULT_CONFIG

    # å¦‚æœop_nameæˆ–task_descä¸ºNoneï¼Œå°è¯•ä»é…ç½®ä¸­è·å–
    if op_name is None:
        op_name = evolve_config.op_name or DEFAULT_OP_NAME
    if task_desc is None:
        task_desc = evolve_config.task_desc or DEFAULT_TASK_DESC.strip()

    print("="*80)
    print("AI KERNEL GENERATOR - è¿›åŒ–å¼ç®—å­ç”Ÿæˆç¤ºä¾‹")
    print("="*80)
    print(f"ç®—å­åç§°: {op_name}")
    print(f"å®ç°ç±»å‹: {evolve_config.dsl}")
    print(f"æ¡†æ¶: {evolve_config.framework}")
    print(f"åç«¯: {evolve_config.backend}")
    print(f"æ¶æ„: {evolve_config.arch}")
    print(f"è¿›åŒ–è½®æ•°: {evolve_config.max_rounds}")
    print(f"å¹¶è¡Œä»»åŠ¡æ•°: {evolve_config.parallel_num}")
    print("="*80)

    # åˆå§‹åŒ–èµ„æº
    task_pool = TaskPool(max_concurrency=evolve_config.parallel_num)
    device_pool = DevicePool(evolve_config.device_list)

    config = load_config(config_path=evolve_config.config_path)
    check_env_for_task(evolve_config.framework, evolve_config.backend, evolve_config.dsl, config)

    # è¿è¡Œè¿›åŒ–è¿‡ç¨‹
    print("å¼€å§‹è¿›åŒ–è¿‡ç¨‹...")
    evolution_result = await evolve(
        op_name=op_name,
        task_desc=task_desc,
        dsl=evolve_config.dsl,
        framework=evolve_config.framework,
        backend=evolve_config.backend,
        arch=evolve_config.arch,
        config=config,
        device_pool=device_pool,
        task_pool=task_pool,
        max_rounds=evolve_config.max_rounds,
        parallel_num=evolve_config.parallel_num
    )

    # æ£€æŸ¥è¿›åŒ–ç»“æœæ˜¯å¦æœ‰æ•ˆ
    if not evolution_result:
        print("\nâŒ è¿›åŒ–è¿‡ç¨‹è¿”å›ç©ºç»“æœ")
        return None

    # è¾“å‡ºè¿›åŒ–ç»“æœ
    print("\n" + "="*80)
    print("è¿›åŒ–å®Œæˆï¼æœ€ç»ˆç»“æœæ±‡æ€»:")
    print("="*80)
    print(f"ç®—å­åç§°: {evolution_result.get('op_name', 'Unknown')}")
    print(f"æ€»è½®æ•°: {evolution_result.get('total_rounds', 0)}")
    print(f"æ€»ä»»åŠ¡æ•°: {evolution_result.get('total_tasks', 0)}")
    print(f"æˆåŠŸä»»åŠ¡æ•°: {evolution_result.get('successful_tasks', 0)}")
    print(f"æœ€ç»ˆæˆåŠŸç‡: {evolution_result.get('final_success_rate', 0.0):.2%}")
    print(f"æœ€ä½³æˆåŠŸç‡: {evolution_result.get('best_success_rate', 0.0):.2%}")
    print(f"å®ç°ç±»å‹: {evolution_result.get('implementation_type', 'Unknown')}")
    print(f"æ¡†æ¶: {evolution_result.get('framework', 'Unknown')}")
    print(f"åç«¯: {evolution_result.get('backend', 'Unknown')}")
    print(f"æ¶æ„: {evolution_result.get('architecture', 'Unknown')}")

    # æ˜¾ç¤ºå­˜å‚¨ç›®å½•ä¿¡æ¯
    storage_dir = evolution_result.get('storage_dir', '')
    if storage_dir:
        print(f"å­˜å‚¨ç›®å½•: {storage_dir}")

    # æ˜¾ç¤ºæœ€ä½³å®ç°
    best_implementations = evolution_result.get('best_implementations', [])
    if best_implementations:
        print(f"\næœ€ä½³å®ç° (å‰{len(best_implementations)}ä¸ª):")
        for i, impl in enumerate(best_implementations, 1):
            profile_data = impl.get('profile', float('inf'))

            # å¤„ç†profileä¿¡æ¯ï¼Œæ”¯æŒä¸‰å…ƒç»„æ ¼å¼
            if isinstance(profile_data, (list, tuple)) and len(profile_data) >= 3:
                gen_time, base_time, speedup = profile_data[0], profile_data[1], profile_data[2]
                profile_str = f"ç”Ÿæˆä»£ç : {gen_time:.4f}s, åŸºå‡†ä»£ç : {base_time:.4f}s, åŠ é€Ÿæ¯”: {speedup:.2f}x"
            elif isinstance(profile_data, (list, tuple)) and len(profile_data) >= 1:
                profile_str = f"æ‰§è¡Œæ—¶é—´: {profile_data[0]:.4f}s"
            elif profile_data != float('inf'):
                profile_str = f"æ‰§è¡Œæ—¶é—´: {profile_data:.4f}s"
            else:
                profile_str = "æ€§èƒ½: N/A"

            print(f"  {i}. {impl.get('op_name', 'Unknown')} (è½®æ¬¡ {impl.get('round', 'N/A')}, {profile_str})")
    else:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°æˆåŠŸçš„å®ç°")

    # æ˜¾ç¤ºæ¯è½®è¯¦ç»†ç»“æœ
    round_results = evolution_result.get('round_results', [])
    if round_results:
        print(f"\næ¯è½®è¯¦ç»†ç»“æœ:")
        for round_result in round_results:
            round_num = round_result.get('round', 'N/A')
            success_rate = round_result.get('success_rate', 0.0)
            successful = round_result.get('successful_tasks', 0)
            total = round_result.get('total_tasks', 0)
            round_best_speedup = round_result.get('round_best_speedup', 0.0)
            global_best_speedup = round_result.get('global_best_speedup', 0.0)

            print(f"  è½®æ¬¡ {round_num}: {successful}/{total} æˆåŠŸ ({success_rate:.2%}), "
                  f"æœ¬è½®æœ€ä½³: {round_best_speedup:.2f}x, å…¨å±€æœ€ä½³: {global_best_speedup:.2f}x")

    # æ˜¾ç¤ºåŠ é€Ÿæ¯”ç»Ÿè®¡æ±‡æ€»
    round_best_speedups = evolution_result.get('round_best_speedups', [])
    global_best_speedup_history = evolution_result.get('global_best_speedup_history', [])
    final_best_speedup = evolution_result.get('final_best_speedup', 0.0)

    if round_best_speedups:
        print(f"\nğŸš€ åŠ é€Ÿæ¯”ç»Ÿè®¡æ±‡æ€»:")
        print(f"  æ¯è½®æœ€ä½³åŠ é€Ÿæ¯”: {[f'{x:.2f}x' for x in round_best_speedups]}")
        print(f"  æˆªè‡³æ¯è½®å…¨å±€æœ€ä½³: {[f'{x:.2f}x' for x in global_best_speedup_history]}")
        print(f"  æœ€ç»ˆå…¨å±€æœ€ä½³åŠ é€Ÿæ¯”: {final_best_speedup:.2f}x")

        # è®¡ç®—åŠ é€Ÿæ¯”æ”¹è¿›è¶‹åŠ¿
        if len(round_best_speedups) > 1:
            improvements = []
            for i in range(1, len(round_best_speedups)):
                if round_best_speedups[i] > round_best_speedups[i-1]:
                    improvements.append(f"è½®æ¬¡{i+1}")
            if improvements:
                print(f"  æ€§èƒ½æ”¹è¿›è½®æ¬¡: {', '.join(improvements)}")

    print("="*80)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    timestamp_str = datetime.now().strftime("%Y%m%d%H%M")
    file_name = f"evolve_result_{evolution_result.get('op_name', 'unknown')}_{evolve_config.dsl}_{evolve_config.framework}_{timestamp_str}.json"
    result_file = Path(config.get("log_dir", "")) / file_name

    # ä¸ºäº†JSONåºåˆ—åŒ–ï¼Œéœ€è¦å¤„ç†å¯èƒ½åŒ…å«ä¸å¯åºåˆ—åŒ–å¯¹è±¡çš„task_infoå­—æ®µ
    serializable_result = evolution_result.copy()
    if 'best_implementations' in serializable_result:
        serializable_implementations = []
        for impl in serializable_result['best_implementations']:
            serializable_impl = impl.copy()
            # ä»task_infoä¸­æå–å…³é”®ä»£ç ä¿¡æ¯ï¼Œç„¶åç§»é™¤æ•´ä¸ªtask_infoå­—æ®µ
            if 'task_info' in serializable_impl:
                task_info = serializable_impl['task_info']
                # æå–å…³é”®ä»£ç å­—æ®µ
                serializable_impl['designer_code'] = task_info.get('designer_code', '')
                serializable_impl['coder_code'] = task_info.get('coder_code', '')
                serializable_impl['task_desc'] = task_info.get('task_desc', '')
                serializable_impl['verifier_result'] = task_info.get('verifier_result', False)
                serializable_impl['verifier_error'] = task_info.get('verifier_error', '')
                # ç§»é™¤å¤æ‚çš„task_infoå¯¹è±¡
                del serializable_impl['task_info']

            # ç¡®ä¿profileä¸‰å…ƒç»„å¯ä»¥JSONåºåˆ—åŒ–
            if 'profile' in serializable_impl and isinstance(serializable_impl['profile'], tuple):
                serializable_impl['profile'] = list(serializable_impl['profile'])
            serializable_implementations.append(serializable_impl)
        serializable_result['best_implementations'] = serializable_implementations

    # å¤„ç†round_resultsä¸­çš„implementations
    if 'round_results' in serializable_result:
        serializable_rounds = []
        for round_result in serializable_result['round_results']:
            serializable_round = round_result.copy()
            if 'implementations' in serializable_round:
                serializable_impls = []
                for impl in serializable_round['implementations']:
                    serializable_impl = impl.copy()
                    # ä»task_infoä¸­æå–å…³é”®ä»£ç ä¿¡æ¯ï¼Œç„¶åç§»é™¤æ•´ä¸ªtask_infoå­—æ®µ
                    if 'task_info' in serializable_impl:
                        task_info = serializable_impl['task_info']
                        # æå–å…³é”®ä»£ç å­—æ®µ
                        serializable_impl['designer_code'] = task_info.get('designer_code', '')
                        serializable_impl['coder_code'] = task_info.get('coder_code', '')
                        serializable_impl['task_desc'] = task_info.get('task_desc', '')
                        serializable_impl['verifier_result'] = task_info.get('verifier_result', False)
                        serializable_impl['verifier_error'] = task_info.get('verifier_error', '')
                        # ç§»é™¤å¤æ‚çš„task_infoå¯¹è±¡
                        del serializable_impl['task_info']

                    # ç¡®ä¿profileä¸‰å…ƒç»„å¯ä»¥JSONåºåˆ—åŒ–
                    if 'profile' in serializable_impl and isinstance(serializable_impl['profile'], tuple):
                        serializable_impl['profile'] = list(serializable_impl['profile'])
                    serializable_impls.append(serializable_impl)
                serializable_round['implementations'] = serializable_impls
            serializable_rounds.append(serializable_round)
        serializable_result['round_results'] = serializable_rounds

    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(serializable_result, f, indent=2, ensure_ascii=False)
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    return evolution_result


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) == 1:
        # æ— å‚æ•°æ¨¡å¼ï¼šä½¿ç”¨ç¡¬ç¼–ç çš„é»˜è®¤é…ç½®
        op_name = DEFAULT_OP_NAME
        task_desc = DEFAULT_TASK_DESC.strip()
        config = DEFAULT_CONFIG

        print(f"ä½¿ç”¨é»˜è®¤ç¡¬ç¼–ç ä»»åŠ¡: {op_name}")
        print("ä»»åŠ¡æè¿°: ä½¿ç”¨å†…ç½®é»˜è®¤ä»»åŠ¡")

    elif len(sys.argv) == 10:
        # batch_runnerè°ƒç”¨æ¨¡å¼: op_name task_file device max_rounds parallel_num dsl framework backend arch
        op_name = sys.argv[1]
        task_file = sys.argv[2]
        device = int(sys.argv[3])
        max_rounds = int(sys.argv[4])
        parallel_num = int(sys.argv[5])
        dsl = sys.argv[6]
        framework = sys.argv[7]
        backend = sys.argv[8]
        arch = sys.argv[9]

        # åˆ›å»ºé…ç½®å¯¹è±¡
        config = EvolveConfig(
            dsl=dsl,
            framework=framework,
            backend=backend,
            arch=arch,
            max_rounds=max_rounds,
            parallel_num=parallel_num,
            device_list=[device],
            config_path=""  # å°†åœ¨__post_init__ä¸­è‡ªåŠ¨è®¾ç½®
        )

        # è¯»å–ä»»åŠ¡æè¿°æ–‡ä»¶
        try:
            with open(task_file, 'r', encoding='utf-8') as f:
                task_desc = f.read().strip()

            print(f"æ‰¹é‡æ¨¡å¼ä»»åŠ¡: {op_name}")
            print(f"ä»»åŠ¡æ–‡ä»¶: {task_file}")
            print(f"è®¾å¤‡: {config.device_list}")
            print(f"é…ç½®: {config.max_rounds}è½®/{config.parallel_num}å¹¶è¡Œ")
            print(f"åŸºç¡€å‚æ•°: {config.dsl}/{config.framework}/{config.backend}/{config.arch}")

        except FileNotFoundError:
            print(f"ä»»åŠ¡æ–‡ä»¶ä¸å­˜åœ¨: {task_file}")
            sys.exit(1)
        except Exception as e:
            print(f"è¯»å–ä»»åŠ¡æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)

    else:
        print("ç”¨æ³•:")
        print("  python run_batch_evolve.py                                                                        # ä½¿ç”¨ç¡¬ç¼–ç é»˜è®¤é…ç½®")
        print("  python run_batch_evolve.py <op_name> <task_file> <device> <rounds> <parallel> <dsl> <framework> <backend> <arch>  # batchæ¨¡å¼")
        sys.exit(1)

    # è¿è¡Œä»»åŠ¡
    try:
        result = asyncio.run(run_custom_evolve(op_name=op_name, task_desc=task_desc, evolve_config=config))

        if result:
            print("\nğŸ‰ è¿›åŒ–å¼ç®—å­ç”ŸæˆæˆåŠŸå®Œæˆ!")
            successful_tasks = result.get('successful_tasks', 0)
            if successful_tasks > 0:
                print(f"âœ… æˆåŠŸç”Ÿæˆäº† {successful_tasks} ä¸ªæœ‰æ•ˆçš„ç®—å­å®ç°")
            else:
                print("âš ï¸  æœªèƒ½ç”ŸæˆæˆåŠŸçš„ç®—å­å®ç°ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä»»åŠ¡æè¿°")
        else:
            print("\nâŒ è¿›åŒ–è¿‡ç¨‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")

    except Exception as e:
        print(f"Error occurred during evolution: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
