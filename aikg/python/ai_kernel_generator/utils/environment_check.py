# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import importlib
import subprocess
import logging
import yaml
import requests
from pathlib import Path
import urllib3

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

logger = logging.getLogger(__name__)


def check_env(framework=None, backend=None, dsl=None, config_path=None, config=None):
    """
    æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ»¡è¶³è¦æ±‚
    
    Args:
        framework: æ¡†æ¶ç±»å‹ (mindspore/torch/numpy)
        backend: åç«¯ç±»å‹ (ascend/cuda/cpu)
        dsl: DSLç±»å‹ (triton/swft)
        config_path: ä»»åŠ¡é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæ£€æŸ¥å…·ä½“ä½¿ç”¨çš„æ¨¡å‹API
        config: å·²åŠ è½½çš„é…ç½®å­—å…¸ï¼Œä¼˜å…ˆäºconfig_pathä½¿ç”¨
    
    Returns:
        bool: ç¯å¢ƒæ£€æŸ¥æ˜¯å¦é€šè¿‡
    """
    print("ğŸ” æ­£åœ¨æ£€æŸ¥ç¯å¢ƒ...")
    issues = []
    
    # 1. æ£€æŸ¥åŸºç¡€åŒ…
    base_packages = ['numpy', 'jinja2', 'httpx']
    for pkg in base_packages:
        try:
            importlib.import_module(pkg)
        except ImportError:
            issues.append(f"âŒ ç¼ºå°‘åŸºç¡€åŒ…: {pkg}")
    
    # 2. æ£€æŸ¥æ¡†æ¶
    if framework == 'mindspore':
        try:
            importlib.import_module('mindspore')
        except ImportError:
            issues.append("âŒ ç¼ºå°‘ mindspore")
    elif framework == 'torch':
        try:
            importlib.import_module('torch')
        except ImportError:
            issues.append("âŒ ç¼ºå°‘ torch")
    
    # 3. æ£€æŸ¥DSL
    if dsl == 'triton':
        try:
            importlib.import_module('triton')
        except ImportError:
            issues.append("âŒ ç¼ºå°‘ triton")
    elif dsl == 'swft':
        try:
            importlib.import_module('swft')
        except ImportError:
            issues.append("âŒ ç¼ºå°‘ swft")
    
    # 4. æ£€æŸ¥ç¡¬ä»¶
    if backend == 'cuda':
        try:
            result = subprocess.run(['nvidia-smi'], capture_output=True, timeout=5)
            if result.returncode != 0:
                issues.append("âš ï¸ CUDAè®¾å¤‡å¯èƒ½ä¸å¯ç”¨")
        except:
            issues.append("âš ï¸ æœªæ‰¾åˆ° nvidia-smi")
    elif backend == 'ascend':
        try:
            result = subprocess.run(['npu-smi', 'info'], capture_output=True, timeout=5)
            if result.returncode != 0:
                issues.append("âš ï¸ æ˜‡è…¾è®¾å¤‡å¯èƒ½ä¸å¯ç”¨")
        except:
            issues.append("âš ï¸ æœªæ‰¾åˆ° npu-smi")
    
    # 5. æ£€æŸ¥APIé…ç½®
    api_ok = _check_llm_api(config_path, config)
    if not api_ok:
        issues.append("âŒ LLM APIé…ç½®æˆ–è¿æ¥æœ‰é—®é¢˜")
    
    # è¾“å‡ºç»“æœ
    if issues:
        print("ğŸš¨ å‘ç°é—®é¢˜:")
        for issue in issues:
            print(f"  {issue}")
        print("\nè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•ã€‚")
        return False
    else:
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡!")
        return True


def _load_llm_config():
    """åŠ è½½LLMé…ç½®æ–‡ä»¶"""
    try:
        # æ‰¾åˆ°llm_config.yamlæ–‡ä»¶
        current_dir = Path(__file__).parent
        config_path = current_dir.parent / "core" / "llm" / "llm_config.yaml"
        
        if not config_path.exists():
            print(f"âš ï¸ æœªæ‰¾åˆ°LLMé…ç½®æ–‡ä»¶: {config_path}")
            return None
            
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            return config
    except Exception as e:
        print(f"âš ï¸ è¯»å–LLMé…ç½®å¤±è´¥: {e}")
        return None


def _check_llm_api(config_path=None, config=None):
    """æ£€æŸ¥LLM APIé…ç½®å’Œè¿æ¥"""
    # åŠ è½½LLMé…ç½®
    llm_config = _load_llm_config()
    if not llm_config:
        return False
    
    # è·å–ä½¿ç”¨çš„æ¨¡å‹é…ç½®
    used_models = set()
    
    if config:
        # ä¼˜å…ˆä½¿ç”¨å·²åŠ è½½çš„é…ç½®å­—å…¸
        if 'agent_model_config' in config:
            agent_configs = config['agent_model_config']
            used_models.update(agent_configs.values())
            print(f"ğŸ” ä»é…ç½®å­—å…¸è¯»å–åˆ°æ¨¡å‹: {', '.join(used_models)}")
        else:
            print("âš ï¸ é…ç½®å­—å…¸ä¸­æœªæ‰¾åˆ°agent_model_configï¼Œè·³è¿‡APIæ£€æŸ¥")
            return True
    elif config_path:
        # å¦‚æœæ²¡æœ‰é…ç½®å­—å…¸ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        task_config = _load_task_config(config_path)
        if task_config and 'agent_model_config' in task_config:
            agent_configs = task_config['agent_model_config']
            used_models.update(agent_configs.values())
            print(f"ğŸ” ä»ä»»åŠ¡é…ç½®æ–‡ä»¶è¯»å–åˆ°æ¨¡å‹: {', '.join(used_models)}")
        else:
            print("âš ï¸ ä»»åŠ¡é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°agent_model_configï¼Œè·³è¿‡APIæ£€æŸ¥")
            return True
    else:
        print("âš ï¸ æœªæä¾›ä»»åŠ¡é…ç½®ï¼Œè·³è¿‡APIæ£€æŸ¥")
        return True
    
    # æ£€æŸ¥æ¯ä¸ªä½¿ç”¨çš„æ¨¡å‹
    all_ok = True
    for model_name in used_models:
        model_config = llm_config.get(model_name)
        if not model_config:
            print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_name}")
            all_ok = False
            continue
            
        print(f"ğŸ” æ£€æŸ¥æ¨¡å‹: {model_name}")
        
        # è·å–å®é™…çš„APIåœ°å€ï¼ˆè€ƒè™‘ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
        actual_api_base = _get_actual_api_base(model_name, model_config)
        if not actual_api_base:
            print(f"âŒ æ¨¡å‹ {model_name} æœªæ‰¾åˆ°APIåœ°å€é…ç½®")
            all_ok = False
            continue
        
        # æ£€æŸ¥APIå¯†é’¥ï¼ˆåªæœ‰éæœ¬åœ°æœåŠ¡æ‰éœ€è¦ï¼‰
        if not model_name.startswith(('ollama_', 'vllm_')):
            api_key_env = model_config.get('api_key_env')
            if api_key_env:
                api_key = os.getenv(api_key_env)
                if not api_key:
                    print(f"âŒ æœªè®¾ç½®APIå¯†é’¥ç¯å¢ƒå˜é‡: {api_key_env}")
                    all_ok = False
                    continue
                print(f"âœ… APIå¯†é’¥å·²é…ç½®: {api_key_env}")
            else:
                print(f"âŒ æ¨¡å‹ {model_name} æœªé…ç½®APIå¯†é’¥ç¯å¢ƒå˜é‡")
                all_ok = False
                continue
        else:
            # æœ¬åœ°æœåŠ¡ï¼ˆå¦‚ollama, vllmï¼‰ä¸éœ€è¦APIå¯†é’¥
            print("â„¹ï¸ æœ¬åœ°æœåŠ¡ï¼Œæ— éœ€APIå¯†é’¥")
        
        if not _test_api_connection(actual_api_base, model_config.get('api_key_env')):
            all_ok = False
    
    return all_ok


def _get_actual_api_base(model_name, model_config):
    """
    è·å–æ¨¡å‹çš„å®é™…APIåœ°å€ï¼Œè€ƒè™‘ç¯å¢ƒå˜é‡è¦†ç›–
    å‚è€ƒmodel_loader.pyçš„é€»è¾‘
    """
    if model_name.startswith("ollama_"):
        # Ollamaæ¨¡å‹ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡AIKG_OLLAMA_API_BASE
        ollama_env = os.getenv("AIKG_OLLAMA_API_BASE")
        if ollama_env:
            print(f"  ä½¿ç”¨ç¯å¢ƒå˜é‡AIKG_OLLAMA_API_BASE: {ollama_env}")
            return ollama_env
        else:
            default_url = "http://localhost:11434"
            print(f"  ç¯å¢ƒå˜é‡AIKG_OLLAMA_API_BASEæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤: {default_url}")
            return default_url
            
    elif model_name.startswith("vllm_"):
        # VLLMæ¨¡å‹ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡AIKG_VLLM_API_BASE
        vllm_env = os.getenv("AIKG_VLLM_API_BASE")
        if vllm_env:
            print(f"  ä½¿ç”¨ç¯å¢ƒå˜é‡AIKG_VLLM_API_BASE: {vllm_env}")
            return vllm_env
        else:
            default_url = "http://localhost:8001/v1"
            print(f"  ç¯å¢ƒå˜é‡AIKG_VLLM_API_BASEæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤: {default_url}")
            return default_url
    else:
        # å…¶ä»–æ¨¡å‹ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„api_base
        api_base = model_config.get('api_base')
        if api_base:
            print(f"  ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIåœ°å€: {api_base}")
        return api_base


def _load_task_config(config_path):
    """åŠ è½½ä»»åŠ¡é…ç½®æ–‡ä»¶"""
    try:
        # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
        if not config_path.startswith('/'):
            # ç›¸å¯¹è·¯å¾„ï¼Œä»é¡¹ç›®æ ¹ç›®å½•å¼€å§‹
            current_dir = Path(__file__).parent
            project_root = current_dir.parent.parent.parent  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
            config_path = project_root / config_path
        else:
            config_path = Path(config_path)
        
        if not config_path.exists():
            print(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡é…ç½®æ–‡ä»¶: {config_path}")
            return None
            
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            return config
    except Exception as e:
        print(f"âš ï¸ è¯»å–ä»»åŠ¡é…ç½®å¤±è´¥: {e}")
        return None


def _test_api_connection(api_base, api_key_env=None):
    """æµ‹è¯•APIè¿æ¥"""
    try:
        # å‡†å¤‡è¯·æ±‚å¤´
        headers = {"Accept": "application/json", "Content-Type": "application/json"}
        if api_key_env:
            api_key = os.getenv(api_key_env)
            if api_key:
                headers["Authorization"] = f"Bearer {api_key}"
        
        # ç»Ÿä¸€å¤„ç†APIåœ°å€ï¼šå»æ‰æ‰€æœ‰è·¯å¾„ï¼Œåªä¿ç•™åè®®å’ŒåŸŸå
        from urllib.parse import urlparse
        parsed = urlparse(api_base)
        base_url = f"{parsed.scheme}://{parsed.netloc}"
        
        # GETè¯·æ±‚ç«¯ç‚¹ï¼ˆé€šå¸¸ç”¨äºè·å–ä¿¡æ¯ï¼‰
        get_endpoints = [
            "/models",                    # é€šç”¨æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹
            "/v1/models",                 # OpenAIæ ¼å¼
            "/v3/models",                 # ç«å±±æ–¹èˆŸå¹³å°æ ¼å¼
            "/api/v1/models",            # æŸäº›æœåŠ¡çš„æ ¼å¼
            "/api/v3/models",            # ç«å±±æ–¹èˆŸå®Œæ•´æ ¼å¼
            "/health",                   # å¥åº·æ£€æŸ¥ç«¯ç‚¹
            "/status",                   # çŠ¶æ€æ£€æŸ¥ç«¯ç‚¹
            "/"                          # æ ¹è·¯å¾„
        ]
        
        # POSTè¯·æ±‚ç«¯ç‚¹ï¼ˆèŠå¤©è¡¥å…¨ï¼Œéœ€è¦å‘é€æµ‹è¯•æ•°æ®ï¼‰
        post_endpoints = [
            ("/chat/completions", {"model": "test", "messages": []}),
            ("/v1/chat/completions", {"model": "test", "messages": []}),
            ("/v3/chat/completions", {"model": "test", "messages": []}),
            ("/api/v3/chat/completions", {"model": "test", "messages": []}),
        ]
        
        success_endpoint = None
        
        # å…ˆå°è¯•GETè¯·æ±‚
        for endpoint in get_endpoints:
            try:
                url = f"{base_url}{endpoint}"
                response = requests.get(url, headers=headers, timeout=10, verify=False)
                
                # æ¥å—å¤šç§æˆåŠŸçŠ¶æ€ç 
                if response.status_code in [200, 201, 202, 204]:
                    success_endpoint = url
                    break
                elif response.status_code == 401:
                    # 401è¡¨ç¤ºç«¯ç‚¹å­˜åœ¨ä½†éœ€è¦è®¤è¯ï¼Œä¹Ÿç®—è¿æ¥æˆåŠŸ
                    success_endpoint = url + " (éœ€è¦è®¤è¯)"
                    break
                    
            except:
                # é™é»˜å¤„ç†æ‰€æœ‰å¼‚å¸¸ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
                continue
        
        # å¦‚æœGETè¯·æ±‚éƒ½å¤±è´¥ï¼Œå°è¯•POSTè¯·æ±‚åˆ°èŠå¤©ç«¯ç‚¹
        if not success_endpoint:
            for endpoint, test_data in post_endpoints:
                try:
                    url = f"{base_url}{endpoint}"
                    response = requests.post(url, headers=headers, json=test_data, timeout=10, verify=False)
                    
                    # å¯¹äºPOSTè¯·æ±‚ï¼Œ400ä¹Ÿç®—æˆåŠŸï¼ˆè¯´æ˜ç«¯ç‚¹å­˜åœ¨ï¼Œåªæ˜¯å‚æ•°ä¸å¯¹ï¼‰
                    if response.status_code in [200, 201, 202, 204, 400, 422]:
                        success_endpoint = url + " (POST)"
                        break
                    elif response.status_code == 401:
                        success_endpoint = url + " (éœ€è¦è®¤è¯)"
                        break
                        
                except:
                    continue
        
        if success_endpoint:
            print(f"âœ… APIè¿æ¥æ­£å¸¸: {success_endpoint}")
            return True
        else:
            print(f"âš ï¸ APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ {base_url} æ˜¯å¦å¯è®¿é—®")
            return False
        
    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False


def check_env_for_task(framework, backend, dsl, config):
    """
    ä¸ºtestsç›®å½•æä¾›çš„ä¾¿æ·ç¯å¢ƒæ£€æŸ¥å‡½æ•°
    å¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºå¼‚å¸¸
    
    Args:
        framework: æ¡†æ¶ç±»å‹
        backend: åç«¯ç±»å‹
        dsl: DSLç±»å‹
        config: é€šè¿‡load_config()åŠ è½½çš„é…ç½®å­—å…¸
    
    Raises:
        RuntimeError: ç¯å¢ƒæ£€æŸ¥å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    success = check_env(
        framework=framework,
        backend=backend,
        dsl=dsl,
        config=config
    )
    if not success:
        raise RuntimeError("ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•")