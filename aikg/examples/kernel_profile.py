# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Kernelæ€§èƒ½å¯¹æ¯”å·¥å…·
ç”¨äºå¯¹æ¯”triton-ascendå’ŒåŸç”Ÿtorch_npuçš„æ€§èƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
1. æ–¹æ³•ä¸€ï¼šç›´æ¥ä¿®æ”¹ä»£ç 
   - ä¿®æ”¹ get_custom_op_torch_code() å‡½æ•°ï¼Œå¡«å…¥ä½ çš„torchå®ç°ä»£ç 
   - ä¿®æ”¹ get_custom_op_triton_code() å‡½æ•°ï¼Œå¡«å…¥ä½ çš„tritonå®ç°ä»£ç 
   - è¿è¡Œ python examples/kernel_profile.py

2. æ–¹æ³•äºŒï¼šé€šè¿‡ç¯å¢ƒå˜é‡è¯»å–ä»£ç 
   - è®¾ç½®ç¯å¢ƒå˜é‡ TORCH_CODE_PATH æŒ‡å‘ä½ çš„torchä»£ç æ–‡ä»¶
   - è®¾ç½®ç¯å¢ƒå˜é‡ TRITON_CODE_PATH æŒ‡å‘ä½ çš„tritonä»£ç æ–‡ä»¶
   - è¿è¡Œ python examples/kernel_profile.py
   
   ç¤ºä¾‹ï¼š
   export TORCH_CODE_PATH="/path/to/your/torch_code.py"
   export TRITON_CODE_PATH="/path/to/your/triton_code.py"
   python examples/kernel_profile.py

3. æ–¹æ³•ä¸‰ï¼šé€šè¿‡å‘½ä»¤è¡Œå‚æ•°ï¼ˆæ¨èï¼‰
   - ä½¿ç”¨ --torch-code-path æŒ‡å®štorchä»£ç æ–‡ä»¶
   - ä½¿ç”¨ --triton-code-path æŒ‡å®štritonä»£ç æ–‡ä»¶
   - ä½¿ç”¨ --op-name æŒ‡å®šç®—å­åç§°
   - å…¶ä»–å¯é€‰å‚æ•°ï¼š--device-id, --run-times, --warmup-times ç­‰
   
   ç¤ºä¾‹ï¼š
   python examples/kernel_profile.py --torch-code-path /path/to/torch_code.py --triton-code-path /path/to/triton_code.py --op-name my_op
   
   æŸ¥çœ‹æ‰€æœ‰å‚æ•°ï¼š
   python examples/kernel_profile.py --help
"""

import os
import argparse
from ai_kernel_generator.core.verifier.kernel_verifier import KernelVerifier
from ai_kernel_generator.config.config_validator import load_config


def get_custom_op_torch_code(torch_code_path=None):
    """è·å–è‡ªå®šä¹‰ç®—å­çš„torchå®ç°ä»£ç ï¼ˆç¤ºä¾‹ï¼šReLUï¼‰"""
    if torch_code_path and os.path.exists(torch_code_path):
        with open(torch_code_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    # é»˜è®¤ä»£ç ï¼ˆå½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰
    return '''
import torch
import torch.nn as nn


class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return torch.relu(x)


batch_size = 16
dim = 16384


def get_inputs():
    x = torch.randn(batch_size, dim)
    return [x]


def get_init_inputs():
    return []  # No special initialization inputs needed
'''


def get_custom_op_triton_code(triton_code_path=None):
    """è·å–è‡ªå®šä¹‰ç®—å­çš„tritonå®ç°ä»£ç ï¼ˆç¤ºä¾‹ï¼šReLUï¼‰"""
    if triton_code_path and os.path.exists(triton_code_path):
        with open(triton_code_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    # é»˜è®¤ä»£ç ï¼ˆå½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰
    return '''
import torch
import triton
import triton.language as tl


@triton.jit
def custom_op_kernel(
    x_ptr,  # è¾“å…¥æŒ‡é’ˆ
    output_ptr,  # è¾“å‡ºæŒ‡é’ˆ
    n_elements,  # æ€»å…ƒç´ æ•°
    BLOCK_SIZE: tl.constexpr,  # æ¯ä¸ªblockå¤„ç†çš„å…ƒç´ æ•°
):
    # è·å–ç¨‹åºID
    pid = tl.program_id(axis=0)
    # è®¡ç®—è¿™ä¸ªblockçš„èµ·å§‹ä½ç½®
    block_start = pid * BLOCK_SIZE
    # åˆ›å»ºåç§»é‡
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    # åˆ›å»ºæ©ç ï¼Œç¡®ä¿ä¸è¶Šç•Œ
    mask = offsets < n_elements

    # åŠ è½½è¾“å…¥æ•°æ®
    x = tl.load(x_ptr + offsets, mask=mask)

    # æ‰§è¡Œè®¡ç®—: è¿™é‡Œæ˜¯ReLUç¤ºä¾‹ max(0, x)
    output = tl.maximum(x, 0.0)

    # å­˜å‚¨ç»“æœ
    tl.store(output_ptr + offsets, output, mask=mask)


def custom_op_triton_torch(x):
    x = x.contiguous()
    n_elements = x.numel()
    output = torch.empty_like(x, device=x.device)

    BLOCK_SIZE = 1024
    grid = (triton.cdiv(n_elements, BLOCK_SIZE),)

    # å¯åŠ¨kernel
    custom_op_kernel[grid](
        x, output, n_elements,
        BLOCK_SIZE=BLOCK_SIZE,
    )

    return output
'''


def run_kernel_profile(
    op_name="custom_op",
    op_task_str=None,
    kernel_code=None,
    framework="torch",
    dsl="triton",
    backend="ascend",
    arch="ascend910b4",
    device_id=0,
    run_times=50,
    warmup_times=5
):
    """
    è¿è¡Œkernelæ€§èƒ½å¯¹æ¯”æµ‹è¯•
    
    Args:
        op_name: ç®—å­åç§°
        op_task_str: æ¡†æ¶å®ç°ä»£ç ï¼ˆå¦‚torchå®ç°ï¼‰
        kernel_code: DSLå®ç°ä»£ç ï¼ˆå¦‚tritonå®ç°ï¼‰
        framework: æ¡†æ¶åç§°ï¼Œé»˜è®¤"torch"
        dsl: DSLåç§°ï¼Œé»˜è®¤"triton"
        backend: åç«¯åç§°ï¼Œé»˜è®¤"ascend"
        arch: æ¶æ„åç§°ï¼Œé»˜è®¤"ascend910b4"
        device_id: è®¾å¤‡IDï¼Œé»˜è®¤0
        run_times: è¿è¡Œæ¬¡æ•°ï¼Œé»˜è®¤50
        warmup_times: é¢„çƒ­æ¬¡æ•°ï¼Œé»˜è®¤5
        
    Returns:
        tuple: (gen_time, base_time, speedup) ç”Ÿæˆä»£ç æ€§èƒ½ã€åŸå§‹æ€§èƒ½ã€åŠ é€Ÿæ¯”
    """
    # åŠ è½½é…ç½®
    config = load_config(dsl)
    
    # åˆ›å»ºéªŒè¯å™¨
    impl_func_name = f"{op_name}_{dsl}_{framework}"
    verifier = KernelVerifier(
        op_name=op_name,
        framework_code=op_task_str,
        task_id="kernel_profile_001",
        framework=framework,
        dsl=dsl,
        backend=backend,
        arch=arch,
        impl_func_name=impl_func_name,
        config=config
    )
    
    task_info = {"coder_code": kernel_code}
    
    # å…ˆè¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿éªŒè¯é€šè¿‡
    print(f"æ­£åœ¨éªŒè¯ {op_name} kernelçš„æ­£ç¡®æ€§...")
    result, error_log = verifier.run(task_info, device_id=device_id)
    if not result:
        print(f"âŒ éªŒè¯å¤±è´¥: {error_log}")
        return None, None, None
    
    print("âœ… æ­£ç¡®æ€§éªŒè¯é€šè¿‡ï¼")
    print("\n" + "="*60)
    print(f"å¼€å§‹æ€§èƒ½æµ‹è¯• (é¢„çƒ­ {warmup_times} æ¬¡ï¼Œæµ‹è¯• {run_times} æ¬¡)")
    print("="*60 + "\n")
    
    # è¿›è¡Œæ€§èƒ½åˆ†æ
    profile_settings = {
        "run_times": run_times,
        "warmup_times": warmup_times
    }
    result = verifier.run_profile(
        current_step=0, device_id=device_id, profile_settings=profile_settings
    )
    gen_time = result['gen_time']
    base_time = result['base_time']
    speedup = result['speedup']
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("æ€§èƒ½æµ‹è¯•ç»“æœ")
    print("="*60)
    print(f"ğŸ“Š åŸç”Ÿ {framework} æ€§èƒ½:     {base_time:.2f} us")
    print(f"ğŸš€ {dsl} kernel æ€§èƒ½:      {gen_time:.2f} us")
    print(f"âš¡ åŠ é€Ÿæ¯”:                 {speedup:.2f}x")
    print("="*60 + "\n")
    
    return gen_time, base_time, speedup


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Kernelæ€§èƒ½å¯¹æ¯”å·¥å…·')
    parser.add_argument('--torch-code-path', type=str, 
                       help='Torchä»£ç æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--triton-code-path', type=str,
                       help='Tritonä»£ç æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--op-name', type=str, default='custom_op',
                       help='ç®—å­åç§° (é»˜è®¤: custom_op)')
    parser.add_argument('--device-id', type=int, default=None,
                       help='è®¾å¤‡ID (é»˜è®¤ä»ç¯å¢ƒå˜é‡DEVICE_IDè·å–)')
    parser.add_argument('--run-times', type=int, default=50,
                       help='è¿è¡Œæ¬¡æ•° (é»˜è®¤: 50)')
    parser.add_argument('--warmup-times', type=int, default=5,
                       help='é¢„çƒ­æ¬¡æ•° (é»˜è®¤: 5)')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•° - è‡ªå®šä¹‰ç®—å­æ€§èƒ½æµ‹è¯•ï¼ˆç¤ºä¾‹ï¼šReLUï¼‰"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # è®¾ç½®è®¾å¤‡IDï¼ˆä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼‰
    if args.device_id is not None:
        device_id = args.device_id
    else:
        device_id = int(os.getenv("DEVICE_ID", "0"))
    
    # è·å–æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼‰
    torch_code_path = args.torch_code_path or os.getenv("TORCH_CODE_PATH")
    triton_code_path = args.triton_code_path or os.getenv("TRITON_CODE_PATH")
    
    # è·å–op_task_strå’Œkernel_code
    # å¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»æ–‡ä»¶è¯»å–ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤ä»£ç 
    op_task_str = get_custom_op_torch_code(torch_code_path)
    kernel_code = get_custom_op_triton_code(triton_code_path)
    
    # æ‰“å°ä½¿ç”¨çš„ä»£ç æ¥æº
    if torch_code_path and os.path.exists(torch_code_path):
        print(f"ğŸ“ ä»æ–‡ä»¶è¯»å– Torch ä»£ç : {torch_code_path}")
    else:
        print("ğŸ“ ä½¿ç”¨é»˜è®¤ Torch ä»£ç ")
        
    if triton_code_path and os.path.exists(triton_code_path):
        print(f"ğŸ“ ä»æ–‡ä»¶è¯»å– Triton ä»£ç : {triton_code_path}")
    else:
        print("ğŸ“ ä½¿ç”¨é»˜è®¤ Triton ä»£ç ")
    
    print(f"ğŸ”§ ç®—å­åç§°: {args.op_name}")
    print(f"ğŸ–¥ï¸  è®¾å¤‡ID: {device_id}")
    print(f"ğŸ”„ è¿è¡Œæ¬¡æ•°: {args.run_times}, é¢„çƒ­æ¬¡æ•°: {args.warmup_times}")
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    run_kernel_profile(
        op_name=args.op_name,
        op_task_str=op_task_str,
        kernel_code=kernel_code,
        framework="torch",
        dsl="triton",
        backend="ascend",
        arch="ascend910b4",
        device_id=device_id,
        run_times=args.run_times,
        warmup_times=args.warmup_times
    )


if __name__ == "__main__":
    main()

