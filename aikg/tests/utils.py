# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os


def _raise_submodule_error(path_name, path_value):
    """é€šç”¨çš„å­æ¨¡å—é”™è¯¯æç¤ºå‡½æ•°"""
    error_msg = f"æ‰¾ä¸åˆ° {path_name}: {path_value}\n"
    error_msg += "è¯·ç¡®ä¿å·²æ­£ç¡®ä¸‹è½½ç›¸å…³å­æ¨¡å—ã€‚\n"
    error_msg += "è§£å†³æ–¹æ¡ˆï¼š\n"
    error_msg += "1. å¦‚æœå·²å…‹éš†ä»“åº“ï¼Œè¯·æ‰§è¡Œï¼šgit submodule update --init --recursive\n"
    error_msg += "2. æˆ–è€…åœ¨aikgç›®å½•ä¸‹æ‰§è¡Œï¼šgit submodule update --init --remote 'thirdparty/*'"
    raise FileNotFoundError(error_msg)


def get_op_task_str(op_name):
    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    task_path = os.path.join(commom_path, 'resources',
                             'task', op_name + '_task.py')
    with open(task_path, "r", encoding="utf-8") as f:
        op_task_str = f.read()
    return op_task_str


def get_kernelbench_task_desc(op_name, framework="torch"):
    """è·å– KernelBench ä»»åŠ¡æè¿°"""
    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    aikg_path = os.path.dirname(commom_path)

    if framework == "torch":
        # Path for torch benchmarks from the KernelBench submodule.
        # The submodule is at `aikg/thirdparty/KernelBench`, and benchmark files are inside `KernelBench/level1/` subdirectory.
        base_dir = os.path.join(
            aikg_path, 'thirdparty', 'KernelBench', 'KernelBench', 'level1')
        # Files are directly in level1 directory with naming pattern: {number}_{name}.py
        task_path = os.path.join(base_dir, op_name + '.py')
    else:
        # Original path for mindspore and numpy benchmarks
        base_dir = os.path.join(aikg_path, 'benchmark',
                                'kernelbench', framework)
        task_path = os.path.join(
            base_dir, op_name, op_name + f'_{framework}.py')

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(task_path):
        if framework == "torch":
            _raise_submodule_error("KernelBench ä»»åŠ¡æ–‡ä»¶", task_path)
        else:
            _raise_submodule_error(f"{framework} benchmark ä»»åŠ¡æ–‡ä»¶", task_path)

    with open(task_path, "r", encoding="utf-8") as f:
        benchmark_task_str = f.read()
    return benchmark_task_str


def get_multikernelbench_task_desc(op_name, framework="torch"):
    """è·å– MultiKernelBench ä»»åŠ¡æè¿°"""
    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    aikg_path = os.path.dirname(commom_path)

    # Path for MultiKernelBench benchmarks from reference directory
    base_path = os.path.join(
        aikg_path, 'thirdparty', 'MultiKernelBench', 'reference')

    # æ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_path):
        _raise_submodule_error("MultiKernelBench ç›®å½•", base_path)

    # Find the file in any category
    for category in os.listdir(base_path):
        category_path = os.path.join(base_path, category)
        if os.path.isdir(category_path):
            task_path = os.path.join(category_path, op_name + '.py')
            if os.path.exists(task_path):
                with open(task_path, "r", encoding="utf-8") as f:
                    return f.read()

    # If not found in any category, raise an error
    _raise_submodule_error(f"MultiKernelBench ä¸­çš„æ“ä½œ {op_name}", f"å·²æœç´¢ç›®å½•: {base_path}")


def get_aikgbench_task_desc(op_name, category=None, framework="torch"):
    """è·å– AIKGBench ä»»åŠ¡æè¿°
    
    Args:
        op_name: ç®—å­åç§°
        framework: æ¡†æ¶åç§°ï¼Œé»˜è®¤ä¸º "torch"
        category: ç±»åˆ«åç§°ï¼Œå¯é€‰å€¼ï¼š'dynamic' æˆ– 'static'ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™æœç´¢æ‰€æœ‰ç±»åˆ«
    """
    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    aikg_path = os.path.dirname(commom_path)

    # Path for AIKGBench benchmarks
    base_path = os.path.join(aikg_path, 'benchmark', 'aikgbench')

    # æ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_path):
        _raise_submodule_error("AIKGBench ç›®å½•", base_path)

    # ç¡®å®šè¦æœç´¢çš„ç±»åˆ«åˆ—è¡¨
    if category:
        if category not in ['dynamic', 'static']:
            raise ValueError(f"æ— æ•ˆçš„ç±»åˆ«å‚æ•°: {category}ï¼Œæœ‰æ•ˆå€¼ä¸º 'dynamic' æˆ– 'static'")
        categories = [f"{category}_shape"]
    else:
        # æœç´¢æ‰€æœ‰ç±»åˆ«
        categories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]

    # æœç´¢æ–‡ä»¶
    for category_dir in categories:
        category_path = os.path.join(base_path, category_dir)
        if not os.path.exists(category_path):
            continue
            
        # éå†å­åˆ†ç±»
        for subcategory in os.listdir(category_path):
            subcategory_path = os.path.join(category_path, subcategory)
            if os.path.isdir(subcategory_path):
                task_path = os.path.join(subcategory_path, op_name + '.py')
                if os.path.exists(task_path):
                    with open(task_path, "r", encoding="utf-8") as f:
                        return f.read()

    # å¦‚æœæœªæ‰¾åˆ°ï¼ŒæŠ›å‡ºé”™è¯¯
    if category:
        _raise_submodule_error(f"AIKGBench ç±»åˆ« {categories[0]} ä¸­çš„æ“ä½œ {op_name}", f"å·²æœç´¢ç›®å½•: {os.path.join(base_path, categories[0])}")
    else:
        _raise_submodule_error(f"AIKGBench ä¸­çš„æ“ä½œ {op_name}", f"å·²æœç´¢ç›®å½•: {base_path}")


def get_kernelbench_op_name(task_index_list, framework="torch"):
    """è·å– KernelBench æ“ä½œåç§°åˆ—è¡¨"""
    if task_index_list is None:
        return None

    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    aikg_path = os.path.dirname(commom_path)

    if framework == "torch":
        task_path = os.path.join(
            aikg_path, 'thirdparty', 'KernelBench', 'KernelBench', 'level1')
        # PyTorch: ç›´æ¥æŸ¥æ‰¾æ–‡ä»¶
        task_prefix_list = [f"{task_index}_" for task_index in task_index_list]
        matched_files = []

        if os.path.exists(task_path):
            for file in os.listdir(task_path):
                if file.endswith('.py') and any(file.startswith(task_prefix) for task_prefix in task_prefix_list):
                    benchmark_name = file[:-3]
                    matched_files.append(benchmark_name)
    else:
        # MindSpore/NumPy: æŸ¥æ‰¾å­ç›®å½•
        task_path = os.path.join(
            aikg_path, 'benchmark', 'kernelbench', framework)
        task_prefix_list = [f"{task_index}_" for task_index in task_index_list]
        matched_files = []

        if os.path.exists(task_path):
            for dir_name in os.listdir(task_path):
                dir_path = os.path.join(task_path, dir_name)
                if os.path.isdir(dir_path) and any(dir_name.startswith(task_prefix) for task_prefix in task_prefix_list):
                    # å¯¹äºMindSporeï¼Œè¿”å›ç›®å½•åä½œä¸ºbenchmark_name
                    matched_files.append(dir_name)

    return matched_files if matched_files else None


def get_multikernelbench_op_name(category="all", framework="torch", op_name=None):
    """è·å– MultiKernelBench æ“ä½œåç§°åˆ—è¡¨"""
    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    aikg_path = os.path.dirname(commom_path)

    # For MultiKernelBench, use category-based reading
    base_path = os.path.join(
        aikg_path, 'thirdparty', 'MultiKernelBench', 'reference')

    # æ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_path):
        _raise_submodule_error("MultiKernelBench ç›®å½•", base_path)

    matched_files = []

    if os.path.exists(base_path):
        if category == "all":
            # Get all available categories
            categories = [d for d in os.listdir(
                base_path) if os.path.isdir(os.path.join(base_path, d))]
        else:
            categories = [category] if os.path.isdir(
                os.path.join(base_path, category)) else []

        for cat in categories:
            category_path = os.path.join(base_path, cat)
            if os.path.exists(category_path):
                for file in os.listdir(category_path):
                    if file.endswith('.py'):
                        # Remove .py extension to get the benchmark name
                        operation_name = file[:-3]

                        # å¦‚æœæŒ‡å®šäº† op_nameï¼Œåªè¿”å›åŒ¹é…çš„ case
                        if op_name is not None:
                            if operation_name == op_name:
                                matched_files.append(operation_name)
                                break  # æ‰¾åˆ°åŒ¹é…çš„å°±åœæ­¢æœç´¢
                        else:
                            matched_files.append(operation_name)

    return matched_files if matched_files else None


def get_aikgbench_op_name(category="all", subcategory="all", framework="torch", op_name=None):
    """è·å– AIKGBench æ“ä½œåç§°åˆ—è¡¨

    Args:
        category: ä¸»åˆ†ç±» ("all", "dynamic", "static")
        subcategory: å­åˆ†ç±» ("all", "attention", "elemwise", "fused", "index", "norm", "reduction", "sorting", "tensor_manipulation", "matmul")
        framework: æ¡†æ¶åç§° (é»˜è®¤ "torch")
        op_name: ç‰¹å®šæ“ä½œåç§° (å¯é€‰)

    Returns:
        list: åŒ¹é…çš„æ“ä½œåç§°åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å› None
    """
    current_file_path = os.path.abspath(__file__)
    commom_path = os.path.dirname(current_file_path)
    aikg_path = os.path.dirname(commom_path)

    # For AIKGBench, use category-based reading
    base_path = os.path.join(aikg_path, 'benchmark', 'aikgbench')

    # æ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_path):
        _raise_submodule_error("AIKGBench ç›®å½•", base_path)

    matched_files = []

    if os.path.exists(base_path):
        if category == "all":
            # Get all available categories (dynamic and static)
            categories = [d for d in os.listdir(
                base_path) if os.path.isdir(os.path.join(base_path, d))]
        else:
            categories = [category] if os.path.isdir(
                os.path.join(base_path, f"{category}_shape")) else []

        for cat in categories:
            category_path = os.path.join(base_path, f"{cat}_shape")
            if os.path.exists(category_path):
                # éå†å­åˆ†ç±» (attention, elemwise, fused, etc.)
                for subcat in os.listdir(category_path):
                    subcat_path = os.path.join(category_path, subcat)
                    if os.path.isdir(subcat_path):
                        # å¦‚æœæŒ‡å®šäº†å­åˆ†ç±»ï¼Œåªå¤„ç†åŒ¹é…çš„å­åˆ†ç±»
                        if subcategory != "all" and subcat != subcategory:
                            continue

                        for file in os.listdir(subcat_path):
                            if file.endswith('.py'):
                                # Remove .py extension to get the benchmark name
                                operation_name = file[:-3]

                                # å¦‚æœæŒ‡å®šäº† op_nameï¼Œåªè¿”å›åŒ¹é…çš„ case
                                if op_name is not None:
                                    if operation_name == op_name:
                                        matched_files.append(operation_name)
                                        break  # æ‰¾åˆ°åŒ¹é…çš„å°±åœæ­¢æœç´¢
                                else:
                                    matched_files.append(operation_name)

    return matched_files if matched_files else None


def add_op_prefix(op_name, benchmark="KernelBench"):
    """ä¸ºæ“ä½œåç§°æ·»åŠ å‰ç¼€ï¼Œæ ¼å¼ï¼šaikg_{benchmark}_{op_name}"""
    return f"aikg_{benchmark.lower()}_{op_name}"


def get_folder_names(folder_path):
    python_files = []

    if os.path.exists(folder_path) and os.path.isdir(folder_path):
        for file in os.listdir(folder_path):
            if file.endswith('.py') and os.path.isfile(os.path.join(folder_path, file)):
                python_files.append(file[:-3])

    return python_files


def get_task_content(folder_path, file_name):
    file_path = os.path.join(folder_path, file_name + '.py')
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except (FileNotFoundError, IOError, UnicodeDecodeError) as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
        return ""


def process_task_results(results, print_summary=True):
    """
    å¤„ç†ä»»åŠ¡è¿è¡Œç»“æœï¼ŒéªŒè¯æ¯ä¸ªop_nameæ˜¯å¦è‡³å°‘æœ‰ä¸€æ¬¡æˆåŠŸã€‚

    Args:
        results: task_pool.wait_all() è¿”å›çš„ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(op_name, result, _), ...]
        print_summary: æ˜¯å¦æ‰“å°ç»“æœæ‘˜è¦

    Returns:
        bool: å¦‚æœæ‰€æœ‰op_nameéƒ½è‡³å°‘æˆåŠŸä¸€æ¬¡è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    from collections import defaultdict

    # æ”¶é›†ç»“æœåˆ°å­—å…¸
    result_dict = defaultdict(int)
    for op_name, result, _ in results:
        result_dict[op_name] += result

    # æ£€æŸ¥å¤±è´¥çš„case - åŒä¸€ä¸ªop_nameåªè¦æœ‰ä¸€æ¬¡æˆåŠŸå°±ç®—é€šè¿‡
    failed_cases = []
    for op_name, success_count in result_dict.items():
        if success_count == 0:  # å¦‚æœæˆåŠŸæ¬¡æ•°ä¸º0ï¼Œè¯´æ˜æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†
            failed_cases.append(op_name)

    # å¯é€‰çš„ç»“æœæ‘˜è¦
    if print_summary:
        total_ops = len(result_dict)
        passed_ops = total_ops - len(failed_cases)
        pass_rate = passed_ops / total_ops if total_ops > 0 else 0.0

        print('-' * 60)
        print(f"ç»“æœå­—å…¸: {dict(result_dict)}")
        print(f"é€šè¿‡çš„æ“ä½œæ•°: {passed_ops}/{total_ops}")
        print(f"é€šè¿‡ç‡: {pass_rate:.2%}")
        if failed_cases:
            print(f"å¤±è´¥çš„æµ‹è¯•case: {failed_cases}")
        print('-' * 60)

    return len(failed_cases) == 0


def generate_beautiful_test_report(results, config, framework, dsl, backend, arch,
                                   save_to_file=True, output_dir=None):
    """
    ç”Ÿæˆç¾è§‚çš„æµ‹è¯•ç»“æœæŠ¥å‘Šï¼ŒåŒ…å«æ§åˆ¶å°è¾“å‡ºå’Œæ–‡ä»¶ä¿å­˜ã€‚

    Args:
        results: task_pool.wait_all() è¿”å›çš„ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(op_name, result, _), ...]
        config: é…ç½®å­—å…¸ï¼Œéœ€è¦åŒ…å« 'log_dir' é”®
        framework: æ¡†æ¶åç§° (å¦‚ "torch", "mindspore")
        dsl: DSLåç§° (å¦‚ "triton_cuda", "triton_ascend", "swft", "tvm")
        backend: åç«¯åç§° (å¦‚ "cuda", "ascend")
        arch: æ¶æ„åç§° (å¦‚ "a100", "910b")
        save_to_file: æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨config['log_dir']

    Returns:
        dict: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    from pathlib import Path

    # ç¡®å®šè¾“å‡ºç›®å½•
    if output_dir is None:
        result_dir = Path(os.path.expanduser(config['log_dir']))
    else:
        result_dir = Path(output_dir)

    # ç»Ÿè®¡æ¯ä¸ªç®—å­çš„é€šè¿‡æ¬¡æ•° (pass@n ç»Ÿè®¡) - ä»åŸå§‹resultsç»Ÿè®¡
    op_stats = {}
    for op_name, result, _ in results:
        base_op_name = op_name  # å¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ç®—å­åç§°æå–é€»è¾‘
        if base_op_name not in op_stats:
            op_stats[base_op_name] = {'passed': 0, 'total': 0}
        op_stats[base_op_name]['total'] += 1
        if result:
            op_stats[base_op_name]['passed'] += 1

    # åˆ†ç±»ç®—å­ï¼šæœ‰é€šè¿‡çš„ vs å®Œå…¨å¤±è´¥çš„
    passed_ops = []  # è‡³å°‘é€šè¿‡1æ¬¡çš„ç®—å­
    failed_ops = []  # å®Œå…¨å¤±è´¥çš„ç®—å­

    for op_name, stats in op_stats.items():
        if stats['passed'] > 0:
            passed_ops.append((op_name, stats['passed'], stats['total']))
        else:
            failed_ops.append((op_name, stats['passed'], stats['total']))

    # æå–orderå¹¶æŒ‰orderæ’åºçš„å‡½æ•°
    def extract_order(op_name):
        try:
            # ä» aikg_{order}_{op_name} æ ¼å¼ä¸­æå– order
            if op_name.startswith('aikg_'):
                parts = op_name.split('_', 2)  # åˆ†å‰²æˆ ['aikg', 'order', 'op_name']
                if len(parts) >= 2:
                    return int(parts[1])
            return float('inf')  # å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œæ”¾åˆ°æœ€å
        except (ValueError, IndexError):
            return float('inf')  # å¦‚æœè§£æå¤±è´¥ï¼Œæ”¾åˆ°æœ€å

    # æŒ‰orderæ’åº
    passed_ops.sort(key=lambda x: extract_order(x[0]))
    failed_ops.sort(key=lambda x: extract_order(x[0]))

    # æ§åˆ¶å°è¾“å‡º
    print('=' * 80)
    print(f"ğŸš€ Pass@N æµ‹è¯•ç»“æœæŠ¥å‘Š - {framework.upper()} + {dsl.upper()} ({backend.upper()}/{arch.upper()})")
    print('=' * 80)
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   â€¢ æµ‹è¯•ç®—å­æ€»æ•°: {len(op_stats)}")
    print(f"   â€¢ é€šè¿‡ç®—å­æ•°é‡: {len(passed_ops)} âœ…")
    print(f"   â€¢ å¤±è´¥ç®—å­æ•°é‡: {len(failed_ops)} âŒ")
    print(f"   â€¢ ç®—å­é€šè¿‡ç‡: {len(passed_ops)/len(op_stats)*100:.1f}%")
    print('-' * 80)

    if passed_ops:
        print("âœ… é€šè¿‡çš„ç®—å­:")
        for i, (op, passed, total) in enumerate(passed_ops, 1):
            print(f"   {i:2d}. {op} (pass num: {passed}/{total})")

    if failed_ops:
        print(f"\nâŒ å®Œå…¨å¤±è´¥çš„ç®—å­:")
        for i, (op, passed, total) in enumerate(failed_ops, 1):
            print(f"   {i:2d}. {op} (pass num: {passed}/{total})")

    print('=' * 80)

    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
    if save_to_file:
        result_dir.mkdir(parents=True, exist_ok=True)
        with open(result_dir / "test_results.txt", "w", encoding="utf-8") as f:
            f.write("ğŸš€ Pass@N æµ‹è¯•ç»“æœæŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")

            # æµ‹è¯•é…ç½®ä¿¡æ¯
            f.write("ğŸ“‹ æµ‹è¯•é…ç½®:\n")
            f.write(f"   â€¢ æ¡†æ¶: {framework.upper()}\n")
            f.write(f"   â€¢ DSL: {dsl.upper()}\n")
            f.write(f"   â€¢ åç«¯: {backend.upper()}\n")
            f.write(f"   â€¢ æ¶æ„: {arch.upper()}\n\n")

            # ç»Ÿè®¡ä¿¡æ¯
            f.write("ğŸ“Š Pass@N ç»Ÿè®¡:\n")
            f.write(f"   â€¢ æµ‹è¯•ç®—å­æ€»æ•°: {len(op_stats)}\n")
            f.write(f"   â€¢ é€šè¿‡ç®—å­æ•°é‡: {len(passed_ops)} âœ…\n")
            f.write(f"   â€¢ å¤±è´¥ç®—å­æ•°é‡: {len(failed_ops)} âŒ\n")
            f.write(f"   â€¢ ç®—å­é€šè¿‡ç‡: {len(passed_ops)/len(op_stats)*100:.1f}%\n\n")

            # è¯¦ç»†ç»“æœ
            f.write("ğŸ“ è¯¦ç»†ç»“æœ:\n")
            f.write("-" * 60 + "\n")

            if passed_ops:
                f.write("âœ… é€šè¿‡çš„ç®—å­ (æŒ‰orderæ’åº):\n")
                for i, (op, passed, total) in enumerate(passed_ops, 1):
                    f.write(f"   {i:2d}. {op} (pass num: {passed}/{total})\n")
                f.write("\n")

            if failed_ops:
                f.write("âŒ å®Œå…¨å¤±è´¥çš„ç®—å­:\n")
                for i, (op, passed, total) in enumerate(failed_ops, 1):
                    f.write(f"   {i:2d}. {op} (pass num: {passed}/{total})\n")
                f.write("\n")

            # Pass@N ç»Ÿè®¡è¡¨æ ¼
            f.write("ğŸ“Š Pass@N ç»Ÿè®¡è¡¨:\n")
            f.write("-" * 50 + "\n")
            f.write(f"{'ç®—å­åç§°':<30} {'PassNum':<15} {'çŠ¶æ€':<8}\n")
            f.write("-" * 50 + "\n")

            all_ops = passed_ops + failed_ops
            all_ops.sort(key=lambda x: extract_order(x[0]))  # æŒ‰orderæ’åº

            for op, passed, total in all_ops:
                pass_at_n = f"{passed}/{total}"
                status = "âœ… é€šè¿‡" if passed > 0 else "âŒ å¤±è´¥"
                f.write(f"{op:<30} {pass_at_n:<15} {status}\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("æŠ¥å‘Šç”Ÿæˆå®Œæˆ! ğŸ‰\n")

        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° {result_dir}/test_results.txt")
        print('=' * 80)

    # è¿”å›ç»Ÿè®¡ä¿¡æ¯ä¾›è¿›ä¸€æ­¥å¤„ç†
    return {
        'total_ops': len(op_stats),
        'passed_ops': len(passed_ops),
        'failed_ops': len(failed_ops),
        'pass_rate': len(passed_ops) / len(op_stats) if len(op_stats) > 0 else 0.0,
        'op_stats': op_stats,
        'passed_list': passed_ops,
        'failed_list': failed_ops
    }
